{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Inspector","text":"<p>Inspector is a Proof of Concept (POC) for a Python-based web application designed to analyze documents using cutting-edge AI technologies.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Insight Extraction: Leverages large language models (LLMs) for user-driven document analysis, integrated with Azure OpenAI services.</li> <li>Data Privacy: Securely handles sensitive data by identifying and masking personal information (e.g., names, document numbers) before transmission to external services.</li> <li>Backend and Frontend Integration:</li> <li>Backend: Powered by FastAPI.</li> <li>Frontend: Built with Streamlit.</li> <li>Tooling:</li> <li>Redis as a vector database for efficient data retrieval.</li> <li>Apache Tika for extracting information from diverse document formats.</li> <li>Advanced AI Techniques:</li> <li>Retrieval-Augmented Generation (RAG).</li> <li>Advanced prompting strategies like Chain-of-Thought and Tree-of-Thought.</li> </ul>"},{"location":"#azure-openai-integration","title":"Azure OpenAI Integration","text":"<p>The project utilizes Azure OpenAI services for generating insights and embeddings. Ensure the following environment variables are configured:</p> <pre><code>AZURE_OPENAI_API_KEY=\"xxxxx\"\nOPENAI_API_TYPE=\"azure\"\nAZURE_OPENAI_ENDPOINT=\"xxxxx\"\nOPENAI_API_VERSION=\"xxxxx\"\nAZURE_DEPLOYMENT=\"xxxxx\"\nAZURE_EMBEDDING_DEPLOYMENT=\"xxxxx\"\n\n# Other Services Configuration\nAPI_HOST=fastapi\nAPI_PORT=8000\nREDIS_HOST=redis\nREDIS_PORT=6379\nSTREAMLIT_PORT=8501\nTIKA_SERVER_ENDPOINT=\"http://tika:9998/\"\n</code></pre> <p>These environment variables enable seamless interaction with Azure OpenAI endpoints for document analysis and embedding operations.</p>"},{"location":"#libraries-used","title":"Libraries Used","text":"<p>This project leverages the following Python libraries and tools: - python-dotenv: For environment variable management. - openai: For interaction with Azure OpenAI\u2019s GPT models. - numpy: For numerical operations. - langchain-text-splitters: For efficient text chunking. - pytest: For testing. - tiktoken: For tokenizing text for LLM interactions. - fastapi: For building the backend REST API. - uvicorn: ASGI server for FastAPI. - streamlit: For building the frontend interface. - streamlit-option-menu: For adding navigation menus to Streamlit apps. - redis: For caching and database operations. - redisvl: Vector library for similarity search in Redis. - tika: For extracting content from diverse document formats. - aiohttp: For asynchronous HTTP requests. - python-multipart: For handling file uploads.</p>"},{"location":"#infrastructure","title":"Infrastructure","text":"<p>The project uses Docker for deployment, and services are orchestrated using docker-compose. The following services are included: 1. FastAPI: Port: 8997     - Backend REST API 2. Streamlit: Port: 8998     - Frontend of the POC 3. Redis: Port: 8999     - Data volume: redis-data-inspector 4. MkDocs: Port: 8996     - Serves project documentation. 5. Tika: Port: 8995     - Extracts information from documents.</p>"},{"location":"#how-to-run","title":"How to Run","text":"<ol> <li>Clone the repository and navigate to the project directory:</li> </ol> <pre><code>git clone https://github.com/andrecorumba/inspector.git\ncd inspector\n</code></pre> <ol> <li>Ensure you have Docker and Docker Compose installed.</li> <li>Build and start the services:</li> </ol> <pre><code>docker-compose up --build\n</code></pre> <ol> <li>Access the application:</li> <li>FastAPI Backend: http://localhost:8997</li> <li>Streamlit Frontend: http://localhost:8998</li> <li>MkDocs Documentation: http://localhost:8996</li> </ol>"},{"location":"#contributing","title":"Contributing","text":"<p>Feel free to submit issues or pull requests. Contributions are welcome!</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License.</p> <p>Author: Andr\u00e9 Rocha Version: 0.2.0</p> <p>Let me know if there are additional details or edits you'd like!</p>"},{"location":"controller/ct_log/","title":"Ct log","text":""},{"location":"controller/ct_log/#controller.ct_log.get_last_log_message","title":"<code>get_last_log_message(redis_key_status)</code>","text":"<p>Retrieves the last log message from a Redis list.</p> <p>Parameters:</p> Name Type Description Default <code>redis_key_status</code> <code>str</code> <p>The Redis key pointing to the list of log messages.</p> required <p>Returns:</p> Type Description <p>str or None: The last message in the Redis list, or None if the list is empty.</p> Source code in <code>controller/ct_log.py</code> <pre><code>def get_last_log_message(redis_key_status: str):\n    \"\"\"\n    Retrieves the last log message from a Redis list.\n\n    Args:\n        redis_key_status (str): The Redis key pointing to the list of log messages.\n\n    Returns:\n        str or None: The last message in the Redis list, or None if the list is empty.\n    \"\"\"\n\n    last_message = REDIS_CLIENT.lindex(redis_key_status, -1)\n    return last_message\n</code></pre>"},{"location":"controller/ct_log/#controller.ct_log.log_and_store","title":"<code>log_and_store(message, config)</code>","text":"<p>Logs a message and stores it in a Redis list with a timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to be logged and stored.</p> required <code>config</code> <code>AppConfig</code> <p>An application configuration object containing user, task, and analysis details.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>controller/ct_log.py</code> <pre><code>def log_and_store(message: str, config: AppConfig):\n    \"\"\"\n    Logs a message and stores it in a Redis list with a timestamp.\n\n    Args:\n        message (str): The message to be logged and stored.\n        config (AppConfig): An application configuration object containing user, task, and analysis details.\n\n    Returns:\n        None\n    \"\"\"\n\n    redis_key_status = f\"status:{config.user}:{config.task_id}:{config.type_of_analysis}\"\n    timestamp = datetime.now().isoformat()\n    logger.info(message)\n    REDIS_CLIENT.rpush(redis_key_status, f\"{message} at {timestamp}\")\n</code></pre>"},{"location":"controller/ct_prompts/","title":"Ct prompts","text":""},{"location":"controller/ct_response/","title":"Ct response","text":""},{"location":"controller/ct_response/#controller.ct_response.context_controller","title":"<code>context_controller(rag_redis_key)</code>","text":"<p>Retrieves the context associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the context.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The context stored in Redis if found, or a default message ('No context data found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def context_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the context associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the context.\n\n    Returns:\n        Union[Dict[str, Any], str]: The context stored in Redis if found, or a default message ('No context data found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'context', 'No context data found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.detail_controller","title":"<code>detail_controller(rag_redis_key)</code>","text":"<p>Retrieves the detail associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the detail.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The detaul stored in Redis if found, or a default message ('No data found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def detail_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the detail associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the detail.\n\n    Returns:\n        Union[Dict[str, Any], str]: The detaul stored in Redis if found, or a default message ('No data found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'response_json', 'No data found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.evaluation_controller","title":"<code>evaluation_controller(rag_redis_key)</code>","text":"<p>Retrieve evaluation-related fields from Redis.</p> <p>Parameters:</p> Name Type Description Default <code>redis_key</code> <code>str</code> <p>The Redis key for the evaluation.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Dict[str, Any]: A dictionary containing evaluation and observation fields.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def evaluation_controller(rag_redis_key: str, ) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieve evaluation-related fields from Redis.\n\n    Args:\n        redis_key (str): The Redis key for the evaluation.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing evaluation and observation fields.\n    \"\"\"\n    evaluation = {}\n    evaluation['evaluation'] = get_redis_field(rag_redis_key, 'evaluation', 'No evaluation found.')\n    evaluation['observation'] = get_redis_field(rag_redis_key, 'observation', 'No obervation found.')\n    return evaluation\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.evaluation_response","title":"<code>evaluation_response(rag_redis_key, evaluations_items)</code>","text":"<p>Save evaluation data to Redis.</p> <p>Parameters:</p> Name Type Description Default <code>redis_key</code> <code>str</code> <p>The Redis key.</p> required <code>evaluations_items</code> <code>Evaluation</code> <p>The evaluation data.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The Redis key used for saving.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def evaluation_response(rag_redis_key: str, evaluations_items: Evaluation):\n    \"\"\"\n    Save evaluation data to Redis.\n\n    Args:\n        redis_key (str): The Redis key.\n        evaluations_items (Evaluation): The evaluation data.\n\n    Returns:\n        str: The Redis key used for saving.\n    \"\"\"\n    evaluations_dict = evaluations_items.model_dump()\n    try:\n        serialized_evaluations = {k: json.dumps(v) for k, v in evaluations_dict.items()}\n        REDIS_CLIENT.hset(rag_redis_key, mapping=serialized_evaluations)\n        return rag_redis_key\n    except Exception as e:\n        raise\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.file_names_controller","title":"<code>file_names_controller(rag_redis_key)</code>","text":"<p>Retrieves the file names associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the file names.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The file names stored in Redis if found, or a default message ('No file found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def file_names_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the file names associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the file names.\n\n    Returns:\n        Union[Dict[str, Any], str]: The file names stored in Redis if found, or a default message ('No file found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'file_names', 'No file found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.get_redis_field","title":"<code>get_redis_field(rag_redis_key, field_name, not_found_message)</code>","text":"<p>Retrieve a specific field from a Redis hash.</p> <p>Parameters:</p> Name Type Description Default <code>redis_client</code> <code>Redis</code> <p>The Redis client instance.</p> required <code>redis_key</code> <code>str</code> <p>The Redis hash key.</p> required <code>field_name</code> <code>str</code> <p>The field to retrieve.</p> required <code>not_found_message</code> <code>str</code> <p>The message to return if the field is not found.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The value of the field as a dictionary or string,                         or the not_found_message if not found.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def get_redis_field(\n    rag_redis_key: str, field_name: str, not_found_message: str\n) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieve a specific field from a Redis hash.\n\n    Args:\n        redis_client (Redis): The Redis client instance.\n        redis_key (str): The Redis hash key.\n        field_name (str): The field to retrieve.\n        not_found_message (str): The message to return if the field is not found.\n\n    Returns:\n        Union[Dict[str, Any], str]: The value of the field as a dictionary or string,\n                                    or the not_found_message if not found.\n    \"\"\"    \n    value = REDIS_CLIENT.hget(rag_redis_key, field_name)\n    if value is not None:\n        try:\n            value = value.decode('utf-8')\n            value = json.loads(value)\n        except (UnicodeDecodeError, json.JSONDecodeError) as e:\n            value = f\"\"\n    else:\n        value = not_found_message\n    return value\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.message_controller","title":"<code>message_controller(rag_redis_key)</code>","text":"<p>Retrieves the message associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the message.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The message stored in Redis if found, or a default message ('No message found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def message_controller(rag_redis_key: str, ) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the message associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the message.\n\n    Returns:\n        Union[Dict[str, Any], str]: The message stored in Redis if found, or a default message ('No message found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'messages', 'No message found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.response_controller","title":"<code>response_controller(rag_redis_key)</code>","text":"<p>Retrieves the response associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the response.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The response stored in Redis if found, or a default message ('No response found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def response_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the response associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the response.\n\n    Returns:\n        Union[Dict[str, Any], str]: The response stored in Redis if found, or a default message ('No response found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'response', 'No response found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.responses_by_user","title":"<code>responses_by_user(user)</code>","text":"<p>Retrieve all response keys for a given user from Redis.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>The username.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: A list of keys or an error message.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def responses_by_user(user: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieve all response keys for a given user from Redis.\n\n    Args:\n        user (str): The username.\n\n    Returns:\n        Union[Dict[str, Any], str]: A list of keys or an error message.\n    \"\"\"\n    try:\n        keys = REDIS_CLIENT.keys(f\"response:{user}:*\")\n        if not keys:\n            return []\n        return keys\n    except Exception as e:\n        return f\"Erro ao recuperar respostas: {str(e)}\"\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.save_response_to_redis","title":"<code>save_response_to_redis(config, data_to_save)</code>","text":"<p>Save a response to Redis using a hash key.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AppConfig</code> <p>Application configuration.</p> required <code>data_to_save</code> <code>SaveRedisPydantic</code> <p>The data to save.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Redis key used for saving.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def save_response_to_redis(config: AppConfig, data_to_save: SaveRedisPydantic) -&gt; str:\n    \"\"\"\n    Save a response to Redis using a hash key.\n\n    Args:\n        config (AppConfig): Application configuration.\n        data_to_save (SaveRedisPydantic): The data to save.\n\n    Returns:\n        str: The Redis key used for saving.\n    \"\"\"\n    redis_key = f\"response:{config.user}:{config.task_id}:{config.type_of_analysis}\"\n    data_to_save = data_to_save.model_dump()\n    print(f'data_to_save:  {data_to_save}')\n\n    try:\n        REDIS_CLIENT.hset(redis_key, mapping=data_to_save)\n        log_and_store(f\"Concluded at\", config)\n        return redis_key\n    except Exception as e:\n        log_and_store(f\"Error to save on Redis at\", config)\n        raise\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.status_by_user","title":"<code>status_by_user(user)</code>","text":"<p>Retrieve status logs for a user.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>The username.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: A dictionary mapping status keys to log messages or an error message.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def status_by_user(user: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieve status logs for a user.\n\n    Args:\n        user (str): The username.\n\n    Returns:\n        Union[Dict[str, Any], str]: A dictionary mapping status keys to log messages or an error message.\n    \"\"\"\n    try:\n        keys = REDIS_CLIENT.keys(f\"status:{user}:*\")\n\n        if not keys:\n            return []\n\n        status_dict = {}\n        for redis_key_status in keys:\n            last_status = get_last_log_message(redis_key_status)\n            status_dict[redis_key_status] = last_status\n\n        return status_dict\n\n    except Exception as e:\n        return f\"Erro ao recuperar respostas: {str(e)}\"\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.usage_controller","title":"<code>usage_controller(rag_redis_key)</code>","text":"<p>Retrieves the usage associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the response.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The usage stored in Redis if found, or a default message ('No usage data found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def usage_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the usage associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the response.\n\n    Returns:\n        Union[Dict[str, Any], str]: The usage stored in Redis if found, or a default message ('No usage data found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'usage', 'No usage data found.')\n</code></pre>"},{"location":"model/chats/","title":"Chats","text":""},{"location":"model/chats/#model.chats.AzureChatInsight","title":"<code>AzureChatInsight</code>","text":"<p>A class for interacting with Azure OpenAI services to invoke chat-based insights using specified prompts and contexts.</p> <p>Attributes:</p> Name Type Description <code>client_chat</code> <code>AzureOpenAI</code> <p>The AzureOpenAI client initialized with environment variables for API keys and configurations.</p> Source code in <code>model/chats.py</code> <pre><code>class AzureChatInsight:\n    \"\"\"\n    A class for interacting with Azure OpenAI services to invoke chat-based insights using specified prompts and contexts.\n\n    Attributes:\n        client_chat (AzureOpenAI): The AzureOpenAI client initialized with environment variables for API keys and configurations.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"\n        Initializes the AzureChatInsight instance by setting up the AzureOpenAI client using environment variables.\n        \"\"\"\n        self.client_chat = AzureOpenAI(\n            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n            api_version=os.getenv(\"OPENAI_API_VERSION\"),\n            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n            azure_deployment=os.getenv(\"AZURE_DEPLOYMENT\"),\n        )\n\n    def invoke(self, prompt: str, context: str, persona: str)-&gt;str:\n        \"\"\"\n        Invokes the Azure OpenAI chat completion API with a specified prompt, context, and persona.\n\n        Args:\n            prompt (str): The main user input to the chat model.\n            context (str): Additional context to be included in the conversation.\n            persona (str): The system persona or instructions for the model's behavior.\n\n        Returns:\n            str: A JSON representation of the API's response, including the generated content and usage statistics.\n        \"\"\"\n        self.messages = [\n            {\n                \"role\": \"system\",\n                \"content\": persona,\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt + str(context),\n            },\n        ]\n\n        self.completion = self.client_chat.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=self.messages,\n        )\n        self.response = self.completion.choices[0].message.content\n        self.response_json = self.completion.to_json()\n        self.usage = self.completion.usage.to_json()\n        self.context = context\n\n        return self.response_json\n</code></pre>"},{"location":"model/chats/#model.chats.AzureChatInsight.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the AzureChatInsight instance by setting up the AzureOpenAI client using environment variables.</p> Source code in <code>model/chats.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"\n    Initializes the AzureChatInsight instance by setting up the AzureOpenAI client using environment variables.\n    \"\"\"\n    self.client_chat = AzureOpenAI(\n        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n        api_version=os.getenv(\"OPENAI_API_VERSION\"),\n        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n        azure_deployment=os.getenv(\"AZURE_DEPLOYMENT\"),\n    )\n</code></pre>"},{"location":"model/chats/#model.chats.AzureChatInsight.invoke","title":"<code>invoke(prompt, context, persona)</code>","text":"<p>Invokes the Azure OpenAI chat completion API with a specified prompt, context, and persona.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The main user input to the chat model.</p> required <code>context</code> <code>str</code> <p>Additional context to be included in the conversation.</p> required <code>persona</code> <code>str</code> <p>The system persona or instructions for the model's behavior.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A JSON representation of the API's response, including the generated content and usage statistics.</p> Source code in <code>model/chats.py</code> <pre><code>def invoke(self, prompt: str, context: str, persona: str)-&gt;str:\n    \"\"\"\n    Invokes the Azure OpenAI chat completion API with a specified prompt, context, and persona.\n\n    Args:\n        prompt (str): The main user input to the chat model.\n        context (str): Additional context to be included in the conversation.\n        persona (str): The system persona or instructions for the model's behavior.\n\n    Returns:\n        str: A JSON representation of the API's response, including the generated content and usage statistics.\n    \"\"\"\n    self.messages = [\n        {\n            \"role\": \"system\",\n            \"content\": persona,\n        },\n        {\n            \"role\": \"user\",\n            \"content\": prompt + str(context),\n        },\n    ]\n\n    self.completion = self.client_chat.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=self.messages,\n    )\n    self.response = self.completion.choices[0].message.content\n    self.response_json = self.completion.to_json()\n    self.usage = self.completion.usage.to_json()\n    self.context = context\n\n    return self.response_json\n</code></pre>"},{"location":"model/config_schema/","title":"Config schema","text":""},{"location":"model/config_schema/#model.config_schema.AppConfig","title":"<code>AppConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the configuration for an application task.</p> <p>Attributes:</p> Name Type Description <code>user</code> <code>str</code> <p>The user identifier associated with the task.</p> <code>task_id</code> <code>str</code> <p>A unique identifier for the task.</p> <code>type_of_analysis</code> <code>str</code> <p>The type of analysis to be performed.</p> Source code in <code>model/config_schema.py</code> <pre><code>class AppConfig(BaseModel):\n    \"\"\"\n    Represents the configuration for an application task.\n\n    Attributes:\n        user (str): The user identifier associated with the task.\n        task_id (str): A unique identifier for the task.\n        type_of_analysis (str): The type of analysis to be performed.\n    \"\"\"\n    user: str\n    task_id: str\n    type_of_analysis: str\n</code></pre>"},{"location":"model/config_schema/#model.config_schema.Evaluation","title":"<code>Evaluation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an evaluation of a response or task.</p> <p>Attributes:</p> Name Type Description <code>evaluation</code> <code>int</code> <p>The evaluation score given to the response or task.</p> <code>observation</code> <code>Optional[str]</code> <p>Additional observations or notes related to the evaluation, default is None.</p> Source code in <code>model/config_schema.py</code> <pre><code>class Evaluation(BaseModel):\n    \"\"\"\n    Represents an evaluation of a response or task.\n\n    Attributes:\n        evaluation (int): The evaluation score given to the response or task.\n        observation (Optional[str]): Additional observations or notes related to the evaluation, default is None.\n    \"\"\"\n    evaluation: int\n    observation: Optional[str] = None\n</code></pre>"},{"location":"model/config_schema/#model.config_schema.SaveRedisPydantic","title":"<code>SaveRedisPydantic</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a data model for saving responses and related information to Redis.</p> <p>Attributes:</p> Name Type Description <code>response</code> <code>str</code> <p>The response generated by the system.</p> <code>context</code> <code>Optional[str]</code> <p>Additional context for the response, default is an empty string.</p> <code>usage</code> <code>str</code> <p>Usage statistics related to the API call or response.</p> <code>response_json</code> <code>str</code> <p>The JSON representation of the system's response.</p> <code>messages</code> <code>str</code> <p>The messages exchanged during the interaction.</p> <code>type_of_analysis</code> <code>str</code> <p>The type of analysis related to the task.</p> <code>technique</code> <code>Optional[str]</code> <p>The technique used in the analysis, default is an empty string.</p> <code>evaluation</code> <code>Optional[int]</code> <p>An evaluation score for the response, default is 0.</p> <code>observation</code> <code>Optional[str]</code> <p>Observations related to the response, default is an empty string.</p> <code>file_names</code> <code>Optional[str]</code> <p>Names of files related to the response or task, default is an empty string.</p> Source code in <code>model/config_schema.py</code> <pre><code>class SaveRedisPydantic(BaseModel):\n    \"\"\"\n    Represents a data model for saving responses and related information to Redis.\n\n    Attributes:\n        response (str): The response generated by the system.\n        context (Optional[str]): Additional context for the response, default is an empty string.\n        usage (str): Usage statistics related to the API call or response.\n        response_json (str): The JSON representation of the system's response.\n        messages (str): The messages exchanged during the interaction.\n        type_of_analysis (str): The type of analysis related to the task.\n        technique (Optional[str]): The technique used in the analysis, default is an empty string.\n        evaluation (Optional[int]): An evaluation score for the response, default is 0.\n        observation (Optional[str]): Observations related to the response, default is an empty string.\n        file_names (Optional[str]): Names of files related to the response or task, default is an empty string.\n    \"\"\"\n    response: str\n    context: Optional[str] = Field(default=\"\")\n    usage: str\n    response_json: str\n    messages: str\n    type_of_analysis: str\n    technique: Optional[str] = Field(default=\"\")\n    evaluation: Optional[int] = Field(default=0)\n    observation: Optional[str] = Field(default=\"\")\n    file_names: Optional[str] = Field(default=\"\")\n</code></pre>"},{"location":"model/embedding/","title":"Embedding","text":""},{"location":"model/embedding/#model.embedding.InspectorEmbeddings","title":"<code>InspectorEmbeddings</code>","text":"<p>A class to generate and manage embeddings using Azure OpenAI for textual content.</p> <p>Attributes:</p> Name Type Description <code>client</code> <code>AzureOpenAI</code> <p>The AzureOpenAI client configured for embedding generation.</p> <code>embedding_float</code> <code>list</code> <p>The list of generated embeddings in float format.</p> <code>embedding_bytes</code> <code>list</code> <p>The list of generated embeddings in byte format.</p> <code>dimensions</code> <code>int</code> <p>The dimensionality of the generated embeddings.</p> <code>data_to_vectorstore</code> <code>list</code> <p>A list of dictionaries prepared for storing in a vector database.</p> Source code in <code>model/embedding.py</code> <pre><code>class InspectorEmbeddings():\n    \"\"\"\n    A class to generate and manage embeddings using Azure OpenAI for textual content.\n\n    Attributes:\n        client (AzureOpenAI): The AzureOpenAI client configured for embedding generation.\n        embedding_float (list): The list of generated embeddings in float format.\n        embedding_bytes (list): The list of generated embeddings in byte format.\n        dimensions (int): The dimensionality of the generated embeddings.\n        data_to_vectorstore (list): A list of dictionaries prepared for storing in a vector database.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the InspectorEmbeddings instance and configures the Azure OpenAI client.\n        \"\"\"\n        self.client = AzureOpenAI(\n            api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n            api_version = os.getenv(\"OPENAI_API_VERSION\"),\n            azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n            azure_deployment = os.getenv(\"AZURE_EMBEDDING_DEPLOYMENT\"),\n        )\n        self.embedding_float = None\n        self.embedding_bytes = None\n        self.dimensions = None\n        self.data_to_vectorstore = []\n\n    def azure_create_embedding(\n            self, \n            content: str,\n            dimensions: int = 3072,\n            file_name: str = \"file_name\",\n            chunk_size: int = 8000,\n        )-&gt;list:\n        \"\"\"\n        Creates embeddings for the given content using Azure OpenAI.\n\n        Args:\n            content (str): The textual content to generate embeddings for.\n            dimensions (int): The number of dimensions for the embeddings. Defaults to 3072.\n            file_name (str): The name of the file associated with the content. Defaults to \"file_name\".\n            chunk_size (int): The maximum size of text chunks. Defaults to 8000.\n\n        Returns:\n            list: A list of embeddings in float format.\n\n        Raises:\n            RuntimeError: If there is an error during embedding creation.\n        \"\"\"\n        self.text_splitted_list = SplitText(chunk_size).split_text(content)\n\n        # Remove blank items\n        text_list = [item for item in self.text_splitted_list if item]\n\n        # Create embeddings with Azure OpenAI\n        try:\n            self.embedding = self.client.embeddings.create(\n                input=text_list,\n                model='text-embedding-3-large',\n                dimensions=dimensions,\n            )\n        except Exception as e:\n            raise RuntimeError(f\"Error to create embeddings: {e}\")\n\n        self.embedding_float = [emb.embedding for emb in self.embedding.data]\n        self.embedding_bytes = [np.array(emb, dtype=np.float32).tobytes() for emb in self.embedding_float]\n        self.dimensions = len(self.embedding.data[0].embedding)\n        self.text_list = text_list\n        self.file_name = file_name\n\n        return self.embedding_float\n\n    def prepare_data(self)-&gt;list:\n        \"\"\"\n        Prepares the embedding data for storage in a vector database.\n\n        Returns:\n            list: A list of dictionaries containing file information, section number, text, and embedding.\n        \"\"\"\n        for i, text in enumerate(self.text_list):\n            self.data_to_vectorstore.append(\n                {\n                    \"file_name\": self.file_name,\n                    \"section\": i+1,\n                    \"text\": text,\n                    \"embedding\": self.embedding_bytes[i],\n                } \n            )\n        return self.data_to_vectorstore\n</code></pre>"},{"location":"model/embedding/#model.embedding.InspectorEmbeddings.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the InspectorEmbeddings instance and configures the Azure OpenAI client.</p> Source code in <code>model/embedding.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the InspectorEmbeddings instance and configures the Azure OpenAI client.\n    \"\"\"\n    self.client = AzureOpenAI(\n        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n        api_version = os.getenv(\"OPENAI_API_VERSION\"),\n        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n        azure_deployment = os.getenv(\"AZURE_EMBEDDING_DEPLOYMENT\"),\n    )\n    self.embedding_float = None\n    self.embedding_bytes = None\n    self.dimensions = None\n    self.data_to_vectorstore = []\n</code></pre>"},{"location":"model/embedding/#model.embedding.InspectorEmbeddings.azure_create_embedding","title":"<code>azure_create_embedding(content, dimensions=3072, file_name='file_name', chunk_size=8000)</code>","text":"<p>Creates embeddings for the given content using Azure OpenAI.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The textual content to generate embeddings for.</p> required <code>dimensions</code> <code>int</code> <p>The number of dimensions for the embeddings. Defaults to 3072.</p> <code>3072</code> <code>file_name</code> <code>str</code> <p>The name of the file associated with the content. Defaults to \"file_name\".</p> <code>'file_name'</code> <code>chunk_size</code> <code>int</code> <p>The maximum size of text chunks. Defaults to 8000.</p> <code>8000</code> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of embeddings in float format.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If there is an error during embedding creation.</p> Source code in <code>model/embedding.py</code> <pre><code>def azure_create_embedding(\n        self, \n        content: str,\n        dimensions: int = 3072,\n        file_name: str = \"file_name\",\n        chunk_size: int = 8000,\n    )-&gt;list:\n    \"\"\"\n    Creates embeddings for the given content using Azure OpenAI.\n\n    Args:\n        content (str): The textual content to generate embeddings for.\n        dimensions (int): The number of dimensions for the embeddings. Defaults to 3072.\n        file_name (str): The name of the file associated with the content. Defaults to \"file_name\".\n        chunk_size (int): The maximum size of text chunks. Defaults to 8000.\n\n    Returns:\n        list: A list of embeddings in float format.\n\n    Raises:\n        RuntimeError: If there is an error during embedding creation.\n    \"\"\"\n    self.text_splitted_list = SplitText(chunk_size).split_text(content)\n\n    # Remove blank items\n    text_list = [item for item in self.text_splitted_list if item]\n\n    # Create embeddings with Azure OpenAI\n    try:\n        self.embedding = self.client.embeddings.create(\n            input=text_list,\n            model='text-embedding-3-large',\n            dimensions=dimensions,\n        )\n    except Exception as e:\n        raise RuntimeError(f\"Error to create embeddings: {e}\")\n\n    self.embedding_float = [emb.embedding for emb in self.embedding.data]\n    self.embedding_bytes = [np.array(emb, dtype=np.float32).tobytes() for emb in self.embedding_float]\n    self.dimensions = len(self.embedding.data[0].embedding)\n    self.text_list = text_list\n    self.file_name = file_name\n\n    return self.embedding_float\n</code></pre>"},{"location":"model/embedding/#model.embedding.InspectorEmbeddings.prepare_data","title":"<code>prepare_data()</code>","text":"<p>Prepares the embedding data for storage in a vector database.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of dictionaries containing file information, section number, text, and embedding.</p> Source code in <code>model/embedding.py</code> <pre><code>def prepare_data(self)-&gt;list:\n    \"\"\"\n    Prepares the embedding data for storage in a vector database.\n\n    Returns:\n        list: A list of dictionaries containing file information, section number, text, and embedding.\n    \"\"\"\n    for i, text in enumerate(self.text_list):\n        self.data_to_vectorstore.append(\n            {\n                \"file_name\": self.file_name,\n                \"section\": i+1,\n                \"text\": text,\n                \"embedding\": self.embedding_bytes[i],\n            } \n        )\n    return self.data_to_vectorstore\n</code></pre>"},{"location":"model/split_text/","title":"Split text","text":""},{"location":"model/split_text/#model.split_text.SplitText","title":"<code>SplitText</code>","text":"<p>A utility class for splitting large text into smaller chunks using the RecursiveCharacterTextSplitter from the langchain_text_splitters library.</p> <p>Attributes:</p> Name Type Description <code>chunk_size</code> <code>int</code> <p>The maximum size of each text chunk. Defaults to 8000.</p> Source code in <code>model/split_text.py</code> <pre><code>class SplitText:\n    \"\"\"\n    A utility class for splitting large text into smaller chunks using\n    the RecursiveCharacterTextSplitter from the langchain_text_splitters library.\n\n    Attributes:\n        chunk_size (int): The maximum size of each text chunk. Defaults to 8000.\n    \"\"\"\n\n    def __init__(self, chunk_size: int = 8000) -&gt; None:\n        \"\"\"\n        Initializes the SplitText instance with a specified chunk size.\n\n        Args:\n            chunk_size (int): The maximum size of each text chunk. Defaults to 8000.\n        \"\"\"\n\n        self.chunk_size = chunk_size\n\n    def split_text(self, content: str) -&gt; List[str]:\n        \"\"\"\n        Splits the given text into smaller chunks using RecursiveCharacterTextSplitter.\n\n        Args:\n            content (str): The text content to split into chunks.\n\n        Returns:\n            List[str]: A list of text chunks.\n\n        Raises:\n            ValueError: If the 'content' parameter is not a string.\n        \"\"\"\n\n        if not isinstance(content, str):\n            raise ValueError(\"The 'content' parameter must be a string.\")\n\n        splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n            chunk_size=self.chunk_size, chunk_overlap=0\n        )\n        return splitter.split_text(content)\n</code></pre>"},{"location":"model/split_text/#model.split_text.SplitText.__init__","title":"<code>__init__(chunk_size=8000)</code>","text":"<p>Initializes the SplitText instance with a specified chunk size.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_size</code> <code>int</code> <p>The maximum size of each text chunk. Defaults to 8000.</p> <code>8000</code> Source code in <code>model/split_text.py</code> <pre><code>def __init__(self, chunk_size: int = 8000) -&gt; None:\n    \"\"\"\n    Initializes the SplitText instance with a specified chunk size.\n\n    Args:\n        chunk_size (int): The maximum size of each text chunk. Defaults to 8000.\n    \"\"\"\n\n    self.chunk_size = chunk_size\n</code></pre>"},{"location":"model/split_text/#model.split_text.SplitText.split_text","title":"<code>split_text(content)</code>","text":"<p>Splits the given text into smaller chunks using RecursiveCharacterTextSplitter.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The text content to split into chunks.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of text chunks.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the 'content' parameter is not a string.</p> Source code in <code>model/split_text.py</code> <pre><code>def split_text(self, content: str) -&gt; List[str]:\n    \"\"\"\n    Splits the given text into smaller chunks using RecursiveCharacterTextSplitter.\n\n    Args:\n        content (str): The text content to split into chunks.\n\n    Returns:\n        List[str]: A list of text chunks.\n\n    Raises:\n        ValueError: If the 'content' parameter is not a string.\n    \"\"\"\n\n    if not isinstance(content, str):\n        raise ValueError(\"The 'content' parameter must be a string.\")\n\n    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n        chunk_size=self.chunk_size, chunk_overlap=0\n    )\n    return splitter.split_text(content)\n</code></pre>"},{"location":"model/tika/","title":"Tika","text":""},{"location":"model/tika/#model.tika.TikaParser","title":"<code>TikaParser</code>","text":"<p>A class for parsing content from files and file bytes using Apache Tika.</p> <p>Attributes:</p> Name Type Description <code>tika_server</code> <code>str</code> <p>The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.</p> Source code in <code>model/tika.py</code> <pre><code>class TikaParser:\n    \"\"\"\n    A class for parsing content from files and file bytes using Apache Tika.\n\n    Attributes:\n        tika_server (str): The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.\n    \"\"\"\n\n    def __init__(self, tika_server: str = 'http://localhost:8002/') -&gt; None:\n        \"\"\"\n        Initializes the TikaParser instance with a Tika server endpoint and starts the Tika Java Virtual Machine.\n\n        Args:\n            tika_server (str): The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.\n        \"\"\"\n        self.tika_server = tika_server\n        tika.initVM()\n\n    def tika_parser_from_bytes(self, file_binary: bytes) -&gt; str:\n        \"\"\"\n        Parses the content of a file provided as bytes using the Tika server.\n\n        Args:\n            file_binary (bytes): The binary content of the file to parse.\n\n        Returns:\n            str: The parsed content of the file.\n        \"\"\"\n        parsed = parser.from_buffer(string=file_binary, serverEndpoint=self.tika_server)\n        self.content = parsed[\"content\"]\n        return self.content\n\n    def tika_parser_from_file_path(self, file_path: str) -&gt; str:\n        \"\"\"\n        Parses the content of a file provided via file path using the Tika server.\n\n        Args:\n            file_path (str): The path to the file to parse.\n\n        Returns:\n            str: The parsed content of the file.\n        \"\"\"\n        parsed = parser.from_file(filename=file_path, serverEndpoint=self.tika_server)\n        self.content = parsed[\"content\"]\n        return self.content\n\n    def hash_file_bytes(self, file_bytes: bytes) -&gt; str:\n        \"\"\"\n        Generates a SHA-256 hash for the given file bytes.\n\n        Args:\n            file_bytes (bytes): The binary content of the file to hash.\n\n        Returns:\n            str: The SHA-256 hash of the file content.\n        \"\"\"\n        sha256_hash = hashlib.sha256()\n        sha256_hash.update(file_bytes)\n        return sha256_hash.hexdigest()\n</code></pre>"},{"location":"model/tika/#model.tika.TikaParser.__init__","title":"<code>__init__(tika_server='http://localhost:8002/')</code>","text":"<p>Initializes the TikaParser instance with a Tika server endpoint and starts the Tika Java Virtual Machine.</p> <p>Parameters:</p> Name Type Description Default <code>tika_server</code> <code>str</code> <p>The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.</p> <code>'http://localhost:8002/'</code> Source code in <code>model/tika.py</code> <pre><code>def __init__(self, tika_server: str = 'http://localhost:8002/') -&gt; None:\n    \"\"\"\n    Initializes the TikaParser instance with a Tika server endpoint and starts the Tika Java Virtual Machine.\n\n    Args:\n        tika_server (str): The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.\n    \"\"\"\n    self.tika_server = tika_server\n    tika.initVM()\n</code></pre>"},{"location":"model/tika/#model.tika.TikaParser.hash_file_bytes","title":"<code>hash_file_bytes(file_bytes)</code>","text":"<p>Generates a SHA-256 hash for the given file bytes.</p> <p>Parameters:</p> Name Type Description Default <code>file_bytes</code> <code>bytes</code> <p>The binary content of the file to hash.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The SHA-256 hash of the file content.</p> Source code in <code>model/tika.py</code> <pre><code>def hash_file_bytes(self, file_bytes: bytes) -&gt; str:\n    \"\"\"\n    Generates a SHA-256 hash for the given file bytes.\n\n    Args:\n        file_bytes (bytes): The binary content of the file to hash.\n\n    Returns:\n        str: The SHA-256 hash of the file content.\n    \"\"\"\n    sha256_hash = hashlib.sha256()\n    sha256_hash.update(file_bytes)\n    return sha256_hash.hexdigest()\n</code></pre>"},{"location":"model/tika/#model.tika.TikaParser.tika_parser_from_bytes","title":"<code>tika_parser_from_bytes(file_binary)</code>","text":"<p>Parses the content of a file provided as bytes using the Tika server.</p> <p>Parameters:</p> Name Type Description Default <code>file_binary</code> <code>bytes</code> <p>The binary content of the file to parse.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The parsed content of the file.</p> Source code in <code>model/tika.py</code> <pre><code>def tika_parser_from_bytes(self, file_binary: bytes) -&gt; str:\n    \"\"\"\n    Parses the content of a file provided as bytes using the Tika server.\n\n    Args:\n        file_binary (bytes): The binary content of the file to parse.\n\n    Returns:\n        str: The parsed content of the file.\n    \"\"\"\n    parsed = parser.from_buffer(string=file_binary, serverEndpoint=self.tika_server)\n    self.content = parsed[\"content\"]\n    return self.content\n</code></pre>"},{"location":"model/tika/#model.tika.TikaParser.tika_parser_from_file_path","title":"<code>tika_parser_from_file_path(file_path)</code>","text":"<p>Parses the content of a file provided via file path using the Tika server.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the file to parse.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The parsed content of the file.</p> Source code in <code>model/tika.py</code> <pre><code>def tika_parser_from_file_path(self, file_path: str) -&gt; str:\n    \"\"\"\n    Parses the content of a file provided via file path using the Tika server.\n\n    Args:\n        file_path (str): The path to the file to parse.\n\n    Returns:\n        str: The parsed content of the file.\n    \"\"\"\n    parsed = parser.from_file(filename=file_path, serverEndpoint=self.tika_server)\n    self.content = parsed[\"content\"]\n    return self.content\n</code></pre>"},{"location":"model/vector_redis/","title":"Vector redis","text":""},{"location":"model/vector_redis/#model.vector_redis.RedisVectorStore","title":"<code>RedisVectorStore</code>","text":"<p>A class for managing a vector store in Redis, including loading data and creating schemas for embeddings.</p> <p>Attributes:</p> Name Type Description <code>redis_url</code> <code>str</code> <p>The URL for connecting to the Redis instance.</p> <code>index</code> <code>SearchIndex</code> <p>The Redis search index instance.</p> <code>keys</code> <code>list</code> <p>The keys loaded into the Redis vector store.</p> <code>info</code> <code>dict</code> <p>Information about the current Redis search index.</p> Source code in <code>model/vector_redis.py</code> <pre><code>class RedisVectorStore():\n    \"\"\"\n    A class for managing a vector store in Redis, including loading data and creating schemas for embeddings.\n\n    Attributes:\n        redis_url (str): The URL for connecting to the Redis instance.\n        index (SearchIndex): The Redis search index instance.\n        keys (list): The keys loaded into the Redis vector store.\n        info (dict): Information about the current Redis search index.\n    \"\"\"\n\n    def __init__(self, redis_url) -&gt; None:\n        \"\"\"\n        Initializes the RedisVectorStore instance with a Redis URL.\n\n        Args:\n            redis_url (str): The Redis connection URL.\n        \"\"\"\n\n        self.redis_url = redis_url\n        self.index = None\n        self.keys = None\n        self.info = None\n\n    def load_data(self, emb_obj: InspectorEmbeddings, config: AppConfig) -&gt; list:\n        \"\"\"\n        Loads data from an embedding object into the Redis vector store.\n\n        Args:\n            emb_obj (InspectorEmbeddings): The embeddings object containing vector data and dimensions.\n            config (AppConfig): The application configuration object.\n\n        Returns:\n            list: A list of keys corresponding to the loaded data in the Redis store.\n        \"\"\"\n\n        if emb_obj != None:\n            data_to_vectorstore = emb_obj.data_to_vectorstore\n            dimensions = emb_obj.dimensions\n            self.create_schema(config, dimensions)\n            self.keys = self.index.load(data_to_vectorstore)\n            return self.keys\n\n    def create_schema(self, config: AppConfig, dimensions: int = 3072, overwrite: bool = True) -&gt; SearchIndex:\n        \"\"\"\n        Creates a schema in Redis for storing document embeddings.\n\n        Args:\n            config (AppConfig): The application configuration object.\n            dimensions (int): The number of dimensions for the vector embeddings. Defaults to 3072.\n            overwrite (bool): Whether to overwrite an existing schema. Defaults to True.\n\n        Returns:\n            SearchIndex: The Redis search index instance.\n\n        \"\"\"\n\n        schema = {\n            \"index\": {\n                \"name\": f\"document-index:{config.user}:{config.task_id}\",\n                \"prefix\": f\"doc:{config.user}:{config.task_id}\",\n                \"storage_type\": \"hash\", \n            },\n            \"fields\": [\n                {\n                    \"name\": \"file_name\",\n                    \"type\": \"tag\"\n                },\n                {\n                    \"name\": \"section\",\n                    \"type\": \"tag\"\n                },\n                {\n                    \"name\": \"text\", \n                    \"type\": \"text\"\n                },\n                {\n                    \"name\": \"embedding\",\n                    \"type\": \"vector\",\n                    \"attrs\": {\n                        \"dims\": dimensions,\n                        \"distance_metric\": \"cosine\",\n                        \"algorithm\": \"flat\",\n                        \"datatype\": \"float32\",\n                    }\n                },\n            ],\n        }\n        self.index = SearchIndex.from_dict(schema)\n        self.index.connect(self.redis_url)\n        self.index.create(overwrite=overwrite)\n        self.info = self.index.info()\n        return self.index\n</code></pre>"},{"location":"model/vector_redis/#model.vector_redis.RedisVectorStore.__init__","title":"<code>__init__(redis_url)</code>","text":"<p>Initializes the RedisVectorStore instance with a Redis URL.</p> <p>Parameters:</p> Name Type Description Default <code>redis_url</code> <code>str</code> <p>The Redis connection URL.</p> required Source code in <code>model/vector_redis.py</code> <pre><code>def __init__(self, redis_url) -&gt; None:\n    \"\"\"\n    Initializes the RedisVectorStore instance with a Redis URL.\n\n    Args:\n        redis_url (str): The Redis connection URL.\n    \"\"\"\n\n    self.redis_url = redis_url\n    self.index = None\n    self.keys = None\n    self.info = None\n</code></pre>"},{"location":"model/vector_redis/#model.vector_redis.RedisVectorStore.create_schema","title":"<code>create_schema(config, dimensions=3072, overwrite=True)</code>","text":"<p>Creates a schema in Redis for storing document embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AppConfig</code> <p>The application configuration object.</p> required <code>dimensions</code> <code>int</code> <p>The number of dimensions for the vector embeddings. Defaults to 3072.</p> <code>3072</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite an existing schema. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>SearchIndex</code> <code>SearchIndex</code> <p>The Redis search index instance.</p> Source code in <code>model/vector_redis.py</code> <pre><code>def create_schema(self, config: AppConfig, dimensions: int = 3072, overwrite: bool = True) -&gt; SearchIndex:\n    \"\"\"\n    Creates a schema in Redis for storing document embeddings.\n\n    Args:\n        config (AppConfig): The application configuration object.\n        dimensions (int): The number of dimensions for the vector embeddings. Defaults to 3072.\n        overwrite (bool): Whether to overwrite an existing schema. Defaults to True.\n\n    Returns:\n        SearchIndex: The Redis search index instance.\n\n    \"\"\"\n\n    schema = {\n        \"index\": {\n            \"name\": f\"document-index:{config.user}:{config.task_id}\",\n            \"prefix\": f\"doc:{config.user}:{config.task_id}\",\n            \"storage_type\": \"hash\", \n        },\n        \"fields\": [\n            {\n                \"name\": \"file_name\",\n                \"type\": \"tag\"\n            },\n            {\n                \"name\": \"section\",\n                \"type\": \"tag\"\n            },\n            {\n                \"name\": \"text\", \n                \"type\": \"text\"\n            },\n            {\n                \"name\": \"embedding\",\n                \"type\": \"vector\",\n                \"attrs\": {\n                    \"dims\": dimensions,\n                    \"distance_metric\": \"cosine\",\n                    \"algorithm\": \"flat\",\n                    \"datatype\": \"float32\",\n                }\n            },\n        ],\n    }\n    self.index = SearchIndex.from_dict(schema)\n    self.index.connect(self.redis_url)\n    self.index.create(overwrite=overwrite)\n    self.info = self.index.info()\n    return self.index\n</code></pre>"},{"location":"model/vector_redis/#model.vector_redis.RedisVectorStore.load_data","title":"<code>load_data(emb_obj, config)</code>","text":"<p>Loads data from an embedding object into the Redis vector store.</p> <p>Parameters:</p> Name Type Description Default <code>emb_obj</code> <code>InspectorEmbeddings</code> <p>The embeddings object containing vector data and dimensions.</p> required <code>config</code> <code>AppConfig</code> <p>The application configuration object.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of keys corresponding to the loaded data in the Redis store.</p> Source code in <code>model/vector_redis.py</code> <pre><code>def load_data(self, emb_obj: InspectorEmbeddings, config: AppConfig) -&gt; list:\n    \"\"\"\n    Loads data from an embedding object into the Redis vector store.\n\n    Args:\n        emb_obj (InspectorEmbeddings): The embeddings object containing vector data and dimensions.\n        config (AppConfig): The application configuration object.\n\n    Returns:\n        list: A list of keys corresponding to the loaded data in the Redis store.\n    \"\"\"\n\n    if emb_obj != None:\n        data_to_vectorstore = emb_obj.data_to_vectorstore\n        dimensions = emb_obj.dimensions\n        self.create_schema(config, dimensions)\n        self.keys = self.index.load(data_to_vectorstore)\n        return self.keys\n</code></pre>"},{"location":"modules/medical/","title":"Medical","text":""},{"location":"modules/medical/#modules.medical.module_etp_tic","title":"<code>module_etp_tic(config)</code>","text":"<p>Extracts specific medical parameters from a data source using a Redis-based RAG pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AppConfig</code> <p>Configuration object containing user, task, and analysis information.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Redis key associated with the result of the RAG pipeline execution.</p> Source code in <code>modules/medical.py</code> <pre><code>def module_etp_tic(config: AppConfig) -&gt; str:\n    \"\"\"\n    Extracts specific medical parameters from a data source using a Redis-based RAG pipeline.\n\n    Args:\n        config (AppConfig): Configuration object containing user, task, and analysis information.\n\n    Returns:\n        str: The Redis key associated with the result of the RAG pipeline execution.\n    \"\"\"\n\n    query = \"\"\"Extract the par\u00e2meters: Creatinine, Hemoglobin, White Blood Cell Count (WBC),Red Blood Cell Count (RBC)\n\tPlatelet Count, Hematocrit, Glucose, Cholesterol (Total), LDL Cholesterol, HDL Cholesterol, Triglycerides, \n    Urea, Blood Urea Nitrogen (BUN), Liver Function Tests (ALT, AST), Bilirubin (Total and Direct), Albumin, \n    Calcium (Serum), Sodium (Serum), Potassium (Serum), Thyroid Stimulating Hormone (TSH)\"\"\"\n\n    rag_redis_key = ct_rag.base_rag_redis_pipeline_controller(\n        prompt=ct_prompts.PROMPT_MEDIAL,\n        query=query,\n        config=config,\n        redis_client=REDIS_CLIENT,\n        k=6,\n        redis_url=REDIS_URL,\n        chunk_size=4000,\n        )\n\n    return rag_redis_key\n</code></pre>"}]}