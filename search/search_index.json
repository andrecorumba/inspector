{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Inspector","text":"<p>Inspector is a Proof of Concept (POC) for a Python-based web application designed to analyze documents using cutting-edge AI technologies.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#insight-extraction","title":"Insight Extraction","text":"<ul> <li>Large Language Models (LLMs): Utilizes advanced LLMs for user-driven document analysis, seamlessly integrated with Azure OpenAI services.</li> <li>Retrieval-Augmented Generation (RAG): Enhances information retrieval by combining retrieval mechanisms with generative models, enabling more accurate and contextually relevant insights.</li> <li>Prompting Techniques like Tree-of-Thought Prompting to facilitates complex reasoning processes to improve the quality of generated responses.</li> <li>Secure Data Handling: Protects sensitive information by identifying and masking personal data (e.g., names, document numbers) before any transmission to external services, ensuring confidentiality and compliance. (coming soon)</li> </ul>"},{"location":"#integration","title":"Integration","text":"<ul> <li>Apache Tika Integration: Efficiently extracts and processes information from a wide variety of document formats, ensuring versatile data handling.</li> <li>Redis Vector Database: Employs Redis for high-performance vector storage and retrieval, optimizing data management and access speeds.</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<p>The documentation was created using the <code>mkdocs-material</code> and <code>mkdocs-string</code> libraries.</p> <pre><code>https://andrecorumba.github.io/inspector/\n</code></pre>"},{"location":"#libraries-used","title":"Libraries Used","text":"<p>This project leverages the following Python libraries and tools: - python-dotenv: For environment variable management. - openai: For interaction with Azure OpenAI\u2019s GPT models. - numpy: For numerical operations. - langchain-text-splitters: For efficient text chunking. - pytest: For testing. - tiktoken: For tokenizing text for LLM interactions. - fastapi: For building the backend REST API. - uvicorn: ASGI server for FastAPI. - streamlit: For building the frontend interface. - streamlit-option-menu: For adding navigation menus to Streamlit apps. - redis: For caching and database operations. - redisvl: Vector library for similarity search in Redis. - tika: For extracting content from diverse document formats. - aiohttp: For asynchronous HTTP requests. - python-multipart: For handling file uploads.</p>"},{"location":"#infrastructure","title":"Infrastructure","text":"<p>The project uses Docker for deployment, and services are orchestrated using docker-compose. The following services are included: 1. FastAPI: Port: 8997     - Backend REST API 2. Streamlit: Port: 8998     - Frontend of the POC 3. Redis: Port: 8999     - Data volume: redis-data-inspector 4. MkDocs: Port: 8996     - Serves project documentation. 5. Tika: Port: 8995     - Extracts information from documents.</p>"},{"location":"#azure-openai-integration","title":"Azure OpenAI Integration","text":"<p>The project utilizes Azure OpenAI services for generating insights and embeddings. Ensure the following environment variables <code>.env</code> file are configured:</p> <pre><code># If you use Azure services\nAZURE_OPENAI_API_KEY = \"your_api_key_here\"\nOPENAI_API_TYPE = \"azure\"\nAZURE_OPENAI_ENDPOINT = \"https://your_azure_endpointservices.com/\"\nOPENAI_API_VERSION = \"api_version\"\nAZURE_DEPLOYMENT = \"your_azure_azure_chat_deployment_name\"\nAZURE_EMBEDDING_DEPLOYMENT = \"your_azure_embedding_deployment_name\"\n\n# If you use Openai Services\nOPENAI_API_KEY=\"your_api_key_here\"\nMODEL_NAME = \"gpt-4o-mini\" # e.g\n\n# Services\nAPI_HOST=fastapi\nAPI_PORT=8000\nREDIS_HOST=redis\nREDIS_PORT=6379\nREDIS_DB=0\nSTREAMLIT_PORT=8501\nTIKA_SERVER_ENDPOINT='http://tika:9998/'\n</code></pre> <p>These environment variables enable seamless interaction with Azure OpenAI endpoints for document analysis and embedding operations.</p>"},{"location":"#how-to-run","title":"How to Run","text":"<ol> <li>Clone the repository and navigate to the project directory:</li> </ol> <pre><code>git clone https://github.com/andrecorumba/inspector.git\ncd inspector\n</code></pre> <ol> <li>Ensure you have Docker and Docker Compose installed.</li> <li>Build and start the services:</li> </ol> <pre><code>docker-compose up --build\n</code></pre> <ol> <li>Access the application:</li> <li>FastAPI Backend: http://localhost:8997</li> <li>Streamlit Frontend: http://localhost:8998</li> <li>MkDocs Documentation: http://localhost:8996</li> </ol>"},{"location":"#contributing","title":"Contributing","text":"<p>Feel free to submit issues or pull requests. Contributions are welcome!</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License.</p> <p>Author: Andr\u00e9 Rocha Version: 0.2.0</p> <p>Let me know if there are additional details or edits you'd like!</p>"},{"location":"controller/ct_log/","title":"Ct log","text":""},{"location":"controller/ct_log/#controller.ct_log.get_last_log_message","title":"<code>get_last_log_message(redis_key_status)</code>","text":"<p>Retrieves the last log message from a Redis list.</p> <p>Parameters:</p> Name Type Description Default <code>redis_key_status</code> <code>str</code> <p>The Redis key pointing to the list of log messages.</p> required <p>Returns:</p> Type Description <p>str or None: The last message in the Redis list, or None if the list is empty.</p> Source code in <code>controller/ct_log.py</code> <pre><code>def get_last_log_message(redis_key_status: str):\n    \"\"\"\n    Retrieves the last log message from a Redis list.\n\n    Args:\n        redis_key_status (str): The Redis key pointing to the list of log messages.\n\n    Returns:\n        str or None: The last message in the Redis list, or None if the list is empty.\n    \"\"\"\n\n    last_message = REDIS_CLIENT.lindex(redis_key_status, -1)\n    return last_message\n</code></pre>"},{"location":"controller/ct_log/#controller.ct_log.log_and_store","title":"<code>log_and_store(message, config)</code>","text":"<p>Logs a message and stores it in a Redis list with a timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to be logged and stored.</p> required <code>config</code> <code>AppConfig</code> <p>An application configuration object containing user, task, and analysis details.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>controller/ct_log.py</code> <pre><code>def log_and_store(message: str, config: AppConfig):\n    \"\"\"\n    Logs a message and stores it in a Redis list with a timestamp.\n\n    Args:\n        message (str): The message to be logged and stored.\n        config (AppConfig): An application configuration object containing user, task, and analysis details.\n\n    Returns:\n        None\n    \"\"\"\n\n    redis_key_status = f\"status:{config.user}:{config.task_id}:{config.type_of_analysis}\"\n    timestamp = datetime.now().isoformat()\n    logger.info(message)\n    REDIS_CLIENT.rpush(redis_key_status, f\"{message} at {timestamp}\")\n</code></pre>"},{"location":"controller/ct_prompts/","title":"Ct prompts","text":""},{"location":"controller/ct_rag/","title":"Ct rag","text":""},{"location":"controller/ct_rag/#controller.ct_rag.base_rag_redis_pipeline_controller","title":"<code>base_rag_redis_pipeline_controller(prompt, query, config, redis_client, redis_url, k=6, chunk_size=8000, service='azure')</code>","text":"<p>Executes a Retrieval-Augmented Generation (RAG) pipeline with a list of files.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The system prompt for RAG.</p> required <code>query</code> <code>str</code> <p>The user query for retrieving relevant information.</p> required <code>config</code> <code>AppConfig</code> <p>The application configuration object with user, task, and analysis details.</p> required <code>redis_client</code> <code>Redis</code> <p>The Redis client instance.</p> required <code>redis_url</code> <code>str</code> <p>The Redis server URL.</p> required <code>k</code> <code>int</code> <p>The number of top results to retrieve. Defaults to 6.</p> <code>6</code> <code>chunk_size</code> <code>int</code> <p>The maximum chunk size for embeddings. Defaults to 8000. The text-embedding-3-large max inputs are 8191 tokens</p> <code>8000</code> <code>service</code> <code>str</code> <p>Service of the LLM. \"azure\" or \"openai\"</p> <code>'azure'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Redis key where the RAG results are stored.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs during the pipeline execution.</p> Source code in <code>controller/ct_rag.py</code> <pre><code>def base_rag_redis_pipeline_controller(    \n    prompt: str,\n    query: str,\n    config: AppConfig,\n    redis_client: Redis,\n    redis_url: str,\n    k: int = 6,\n    chunk_size: int = 8000,\n    service: str = \"azure\",\n) -&gt; str:\n    \"\"\"\n    Executes a Retrieval-Augmented Generation (RAG) pipeline with a list of files.\n\n    Args:\n        prompt (str): The system prompt for RAG.\n        query (str): The user query for retrieving relevant information.\n        config (AppConfig): The application configuration object with user, task, and analysis details.\n        redis_client (Redis): The Redis client instance.\n        redis_url (str): The Redis server URL.\n        k (int): The number of top results to retrieve. Defaults to 6.\n        chunk_size (int): The maximum chunk size for embeddings. Defaults to 8000. The text-embedding-3-large max inputs are 8191 tokens\n        service (str): Service of the LLM. \"azure\" or \"openai\"\n\n    Returns:\n        str: The Redis key where the RAG results are stored.\n\n    Raises:\n        Exception: If an error occurs during the pipeline execution.\n    \"\"\"\n    redis_key_status = f\"status:{config.user}:{config.task_id}:{config.type_of_analysis}\"\n    sufix = f\"{config.user}:{config.task_id}:{config.type_of_analysis}\"\n    file_list_sufix = f\"file:{sufix}*\"\n\n    try:\n        file_keys_list = redis_client.keys(file_list_sufix)\n        file_name_list = []\n\n        for redis_key_file in file_keys_list:\n            # Creating embeddings\n            log_and_store(f\"Creating Embedding: {redis_key_file}\", config)\n\n            content = redis_client.hget(redis_key_file, 'file').decode('utf-8')\n            file_name = redis_client.hget(redis_key_file, 'file_name').decode('utf-8')\n            embedding = InspectorEmbeddings()\n            embedding.create_embedding(\n                content=content, \n                file_name=file_name, \n                chunk_size=chunk_size, \n                service=service\n                )\n\n            # Load the tokenized content on Redis\n            tokenized_content = str(embedding.text_splitted_list)\n            redis_client.hset(redis_key_file, mapping={'tokenized': tokenized_content})\n\n            # Load embeddings on Redis\n            embedding.prepare_data()\n            vector_store = RedisVectorStore(redis_url=redis_url)\n            vector_store.load_data(embedding, config)\n\n            log_and_store(f\"Embeddings loaded\", config)\n            file_name_list.append(file_name)\n\n        # RAG\n        rag_obj = RAGRedis(\n            config=config, \n            redis_url=redis_url, \n            k=k, \n            service=service\n            )\n\n        rag_obj.rag(query, prompt)\n\n        # Prepare data to save on Redis\n        data_to_save = SaveRedisPydantic(\n            response = json.dumps(rag_obj.response),\n            context =  json.dumps(rag_obj.context),\n            usage =  json.dumps(rag_obj.usage),\n            response_json =  json.dumps(rag_obj.response_json),\n            messages =  json.dumps(rag_obj.messages),\n            type_of_analysis =  json.dumps(config.type_of_analysis),\n            technique = json.dumps(\"RAG\"),\n            evaluation = 0,\n            observation = \"\",\n            file_names = json.dumps(file_name_list)\n        )\n\n        redis_key = ct_response.save_response_to_redis(config, data_to_save )\n        return redis_key\n\n    except Exception as e:\n        raise\n</code></pre>"},{"location":"controller/ct_rag/#controller.ct_rag.save_rag_redis","title":"<code>save_rag_redis(config, rag_obj, redis_client)</code>","text":"<p>Saves the data from a RAGRedis object into Redis using a single hash key.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AppConfig</code> <p>The application configuration object with user, task, and analysis details.</p> required <code>rag_obj</code> <code>RAGRedis</code> <p>The RAGRedis object containing the response and associated data.</p> required <code>redis_client</code> <code>Redis</code> <p>The Redis client instance.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Redis key under which the data is saved.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs during the save operation.</p> Source code in <code>controller/ct_rag.py</code> <pre><code>def save_rag_redis(config: AppConfig, rag_obj: RAGRedis, redis_client: Redis) -&gt; str:\n    \"\"\"\n    Saves the data from a RAGRedis object into Redis using a single hash key.\n\n    Args:\n        config (AppConfig): The application configuration object with user, task, and analysis details.\n        rag_obj (RAGRedis): The RAGRedis object containing the response and associated data.\n        redis_client (Redis): The Redis client instance.\n\n    Returns:\n        str: The Redis key under which the data is saved.\n\n    Raises:\n        Exception: If an error occurs during the save operation.\n    \"\"\"\n    try:\n        redis_key = f\"rag:{config.user}:{config.task_id}:{config.type_of_analysis}\"\n        redis_key_status = f\"status:{config.user}:{config.task_id}:{config.type_of_analysis}\"\n\n        # Serializar os dados para JSON\n        data_to_save = {\n            'response': json.dumps(rag_obj.response),\n            'context': json.dumps(rag_obj.context),\n            'usage': json.dumps(rag_obj.usage),\n            'response_json': json.dumps(rag_obj.response_json),\n            'messages': json.dumps(rag_obj.messages),\n            'type_of_analysis': json.dumps(config.type_of_analysis),\n        }\n\n        # Armazenar todos os dados sob uma \u00fanica chave de hash\n        redis_client.hset(redis_key, mapping=data_to_save)\n        log_and_store(f\"Concluded\", config)\n        return redis_key\n    except Exception as e:\n        # logging.error(f\"Ocorreu um erro ao salvar no Redis: {e}\")\n        log_and_store(f\"RAG: Error to save on Redis: {e}\", config)\n        raise\n</code></pre>"},{"location":"controller/ct_response/","title":"Ct response","text":""},{"location":"controller/ct_response/#controller.ct_response.context_controller","title":"<code>context_controller(rag_redis_key)</code>","text":"<p>Retrieves the context associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the context.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The context stored in Redis if found, or a default message ('No context data found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def context_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the context associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the context.\n\n    Returns:\n        Union[Dict[str, Any], str]: The context stored in Redis if found, or a default message ('No context data found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'context', 'No context data found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.detail_controller","title":"<code>detail_controller(rag_redis_key)</code>","text":"<p>Retrieves the detail associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the detail.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The detaul stored in Redis if found, or a default message ('No data found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def detail_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the detail associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the detail.\n\n    Returns:\n        Union[Dict[str, Any], str]: The detaul stored in Redis if found, or a default message ('No data found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'response_json', 'No data found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.evaluation_controller","title":"<code>evaluation_controller(rag_redis_key)</code>","text":"<p>Retrieve evaluation-related fields from Redis.</p> <p>Parameters:</p> Name Type Description Default <code>redis_key</code> <code>str</code> <p>The Redis key for the evaluation.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Dict[str, Any]: A dictionary containing evaluation and observation fields.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def evaluation_controller(rag_redis_key: str, ) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieve evaluation-related fields from Redis.\n\n    Args:\n        redis_key (str): The Redis key for the evaluation.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing evaluation and observation fields.\n    \"\"\"\n    evaluation = {}\n    evaluation['evaluation'] = get_redis_field(rag_redis_key, 'evaluation', 'No evaluation found.')\n    evaluation['observation'] = get_redis_field(rag_redis_key, 'observation', 'No obervation found.')\n    return evaluation\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.evaluation_response","title":"<code>evaluation_response(rag_redis_key, evaluations_items)</code>","text":"<p>Save evaluation data to Redis.</p> <p>Parameters:</p> Name Type Description Default <code>redis_key</code> <code>str</code> <p>The Redis key.</p> required <code>evaluations_items</code> <code>Evaluation</code> <p>The evaluation data.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The Redis key used for saving.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def evaluation_response(rag_redis_key: str, evaluations_items: Evaluation):\n    \"\"\"\n    Save evaluation data to Redis.\n\n    Args:\n        redis_key (str): The Redis key.\n        evaluations_items (Evaluation): The evaluation data.\n\n    Returns:\n        str: The Redis key used for saving.\n    \"\"\"\n    evaluations_dict = evaluations_items.model_dump()\n    try:\n        serialized_evaluations = {k: json.dumps(v) for k, v in evaluations_dict.items()}\n        REDIS_CLIENT.hset(rag_redis_key, mapping=serialized_evaluations)\n        return rag_redis_key\n    except Exception as e:\n        raise\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.file_names_controller","title":"<code>file_names_controller(rag_redis_key)</code>","text":"<p>Retrieves the file names associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the file names.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The file names stored in Redis if found, or a default message ('No file found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def file_names_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the file names associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the file names.\n\n    Returns:\n        Union[Dict[str, Any], str]: The file names stored in Redis if found, or a default message ('No file found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'file_names', 'No file found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.get_redis_field","title":"<code>get_redis_field(rag_redis_key, field_name, not_found_message)</code>","text":"<p>Retrieve a specific field from a Redis hash.</p> <p>Parameters:</p> Name Type Description Default <code>redis_client</code> <code>Redis</code> <p>The Redis client instance.</p> required <code>redis_key</code> <code>str</code> <p>The Redis hash key.</p> required <code>field_name</code> <code>str</code> <p>The field to retrieve.</p> required <code>not_found_message</code> <code>str</code> <p>The message to return if the field is not found.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The value of the field as a dictionary or string,                         or the not_found_message if not found.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def get_redis_field(\n    rag_redis_key: str, field_name: str, not_found_message: str\n) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieve a specific field from a Redis hash.\n\n    Args:\n        redis_client (Redis): The Redis client instance.\n        redis_key (str): The Redis hash key.\n        field_name (str): The field to retrieve.\n        not_found_message (str): The message to return if the field is not found.\n\n    Returns:\n        Union[Dict[str, Any], str]: The value of the field as a dictionary or string,\n                                    or the not_found_message if not found.\n    \"\"\"    \n    value = REDIS_CLIENT.hget(rag_redis_key, field_name)\n    if value is not None:\n        try:\n            value = value.decode('utf-8')\n            value = json.loads(value)\n        except (UnicodeDecodeError, json.JSONDecodeError) as e:\n            value = f\"\"\n    else:\n        value = not_found_message\n    return value\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.message_controller","title":"<code>message_controller(rag_redis_key)</code>","text":"<p>Retrieves the message associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the message.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The message stored in Redis if found, or a default message ('No message found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def message_controller(rag_redis_key: str, ) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the message associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the message.\n\n    Returns:\n        Union[Dict[str, Any], str]: The message stored in Redis if found, or a default message ('No message found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'messages', 'No message found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.response_controller","title":"<code>response_controller(rag_redis_key)</code>","text":"<p>Retrieves the response associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the response.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The response stored in Redis if found, or a default message ('No response found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def response_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the response associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the response.\n\n    Returns:\n        Union[Dict[str, Any], str]: The response stored in Redis if found, or a default message ('No response found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'response', 'No response found.')\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.responses_by_user","title":"<code>responses_by_user(user)</code>","text":"<p>Retrieve all response keys for a given user from Redis.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>The username.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: A list of keys or an error message.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def responses_by_user(user: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieve all response keys for a given user from Redis.\n\n    Args:\n        user (str): The username.\n\n    Returns:\n        Union[Dict[str, Any], str]: A list of keys or an error message.\n    \"\"\"\n    try:\n        keys = REDIS_CLIENT.keys(f\"response:{user}:*\")\n        if not keys:\n            return []\n        return keys\n    except Exception as e:\n        return f\"Erro ao recuperar respostas: {str(e)}\"\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.save_response_to_redis","title":"<code>save_response_to_redis(config, data_to_save)</code>","text":"<p>Save a response to Redis using a hash key.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AppConfig</code> <p>Application configuration.</p> required <code>data_to_save</code> <code>SaveRedisPydantic</code> <p>The data to save.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Redis key used for saving.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def save_response_to_redis(config: AppConfig, data_to_save: SaveRedisPydantic) -&gt; str:\n    \"\"\"\n    Save a response to Redis using a hash key.\n\n    Args:\n        config (AppConfig): Application configuration.\n        data_to_save (SaveRedisPydantic): The data to save.\n\n    Returns:\n        str: The Redis key used for saving.\n    \"\"\"\n    redis_key = f\"response:{config.user}:{config.task_id}:{config.type_of_analysis}\"\n    data_to_save = data_to_save.model_dump()\n    # print(f'data_to_save:  {data_to_save}')\n\n    try:\n        REDIS_CLIENT.hset(redis_key, mapping=data_to_save)\n        log_and_store(f\"Concluded\", config)\n        return redis_key\n    except Exception as e:\n        log_and_store(f\"Error to save on Redis\", config)\n        raise\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.status_by_user","title":"<code>status_by_user(user)</code>","text":"<p>Retrieve status logs for a user.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>The username.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: A dictionary mapping status keys to log messages or an error message.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def status_by_user(user: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieve status logs for a user.\n\n    Args:\n        user (str): The username.\n\n    Returns:\n        Union[Dict[str, Any], str]: A dictionary mapping status keys to log messages or an error message.\n    \"\"\"\n    try:\n        keys = REDIS_CLIENT.keys(f\"status:{user}:*\")\n\n        if not keys:\n            return []\n\n        status_dict = {}\n        for redis_key_status in keys:\n            last_status = get_last_log_message(redis_key_status)\n            status_dict[redis_key_status] = last_status\n\n        return status_dict\n\n    except Exception as e:\n        return f\"Erro ao recuperar respostas: {str(e)}\"\n</code></pre>"},{"location":"controller/ct_response/#controller.ct_response.usage_controller","title":"<code>usage_controller(rag_redis_key)</code>","text":"<p>Retrieves the usage associated with a given Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>The Redis key used to look up the response.</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], str]</code> <p>Union[Dict[str, Any], str]: The usage stored in Redis if found, or a default message ('No usage data found.') if not.</p> Source code in <code>controller/ct_response.py</code> <pre><code>def usage_controller(rag_redis_key: str) -&gt; Union[Dict[str, Any], str]:\n    \"\"\"\n    Retrieves the usage associated with a given Redis key.\n\n    Args:\n        rag_redis_key (str): The Redis key used to look up the response.\n\n    Returns:\n        Union[Dict[str, Any], str]: The usage stored in Redis if found, or a default message ('No usage data found.') if not.\n    \"\"\"\n    return get_redis_field(rag_redis_key, 'usage', 'No usage data found.')\n</code></pre>"},{"location":"controller/ct_upload/","title":"Ct upload","text":""},{"location":"controller/ct_upload/#controller.ct_upload.upload_controller","title":"<code>upload_controller(file_bytes, file_name, config)</code>","text":"<p>Handles the processing of an uploaded file, including content extraction, embedding creation,  and storage in Redis.</p> <p>Parameters:</p> Name Type Description Default <code>file_bytes</code> <code>bytes</code> <p>The binary content of the uploaded file.</p> required <code>file_name</code> <code>str</code> <p>The name of the uploaded file.</p> required <code>config</code> <code>AppConfig</code> <p>The configuration object containing user, task, and analysis details.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The Redis key for the saved file data, or None if an error occurs during processing.</p> Source code in <code>controller/ct_upload.py</code> <pre><code>def upload_controller(file_bytes: bytes, file_name: str, config: AppConfig) -&gt; Any:\n    \"\"\"\n    Handles the processing of an uploaded file, including content extraction, embedding creation, \n    and storage in Redis.\n\n    Args:\n        file_bytes (bytes): The binary content of the uploaded file.\n        file_name (str): The name of the uploaded file.\n        config (AppConfig): The configuration object containing user, task, and analysis details.\n\n    Returns:\n        Any: The Redis key for the saved file data, or None if an error occurs during processing.\n    \"\"\"\n\n    sufix = f\"{config.user}:{config.task_id}:{config.type_of_analysis}\"\n\n    try:\n        # Analyze the file content using Tika\n        tika_parser = TikaParser(tika_server=TIKA_SERVER_ENDPOINT)\n        content = tika_parser.tika_parser_from_bytes(file_bytes)\n        file_hash = tika_parser.hash_file_bytes(file_bytes)\n\n        # Take only the first 16 characters of the hash\n        redis_key_file = f\"file:{sufix}:{file_hash[:16]}\"\n\n        log_and_store(f\"Tika: Extracted file {file_name}\", config)\n\n        if content is None:\n            log_and_store(f\"Tika: Error extracting file {file_name}\", config)\n            return\n\n        # Store the parsed content in Redis\n        REDIS_CLIENT.hset(redis_key_file, mapping={\n            'file_name': file_name,\n            'file': content,\n            'tokenized': '',\n            })\n        log_and_store(f\"Tika: File saved: {redis_key_file}\", config)\n\n        return redis_key_file\n\n    except Exception as e:\n        log_and_store(f\"Tika: Error in upload_controller: {e}\", config)\n        raise\n</code></pre>"},{"location":"model/chats/","title":"Chats","text":""},{"location":"model/config_schema/","title":"Config schema","text":""},{"location":"model/config_schema/#model.config_schema.AppConfig","title":"<code>AppConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the configuration for an application task.</p> <p>Attributes:</p> Name Type Description <code>user</code> <code>str</code> <p>The user identifier associated with the task.</p> <code>task_id</code> <code>str</code> <p>A unique identifier for the task.</p> <code>type_of_analysis</code> <code>str</code> <p>The type of analysis to be performed.</p> <code>service</code> <code>str</code> <p>Service of the LLM. \"azure\" or \"openai\"</p> Source code in <code>model/config_schema.py</code> <pre><code>class AppConfig(BaseModel):\n    \"\"\"\n    Represents the configuration for an application task.\n\n    Attributes:\n        user (str): The user identifier associated with the task.\n        task_id (str): A unique identifier for the task.\n        type_of_analysis (str): The type of analysis to be performed.\n        service (str): Service of the LLM. \"azure\" or \"openai\"\n    \"\"\"\n    user: str\n    task_id: str\n    type_of_analysis: Optional[str] = Field(default=\"document\")\n    service: Optional[str] = Field(default=\"azure\")\n    language: Optional[str] = Field(default=\"english\")\n</code></pre>"},{"location":"model/config_schema/#model.config_schema.Evaluation","title":"<code>Evaluation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an evaluation of a response or task.</p> <p>Attributes:</p> Name Type Description <code>evaluation</code> <code>int</code> <p>The evaluation score given to the response or task.</p> <code>observation</code> <code>Optional[str]</code> <p>Additional observations or notes related to the evaluation, default is None.</p> Source code in <code>model/config_schema.py</code> <pre><code>class Evaluation(BaseModel):\n    \"\"\"\n    Represents an evaluation of a response or task.\n\n    Attributes:\n        evaluation (int): The evaluation score given to the response or task.\n        observation (Optional[str]): Additional observations or notes related to the evaluation, default is None.\n    \"\"\"\n    evaluation: int\n    observation: Optional[str] = None\n</code></pre>"},{"location":"model/config_schema/#model.config_schema.SaveRedisPydantic","title":"<code>SaveRedisPydantic</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a data model for saving responses and related information to Redis.</p> <p>Attributes:</p> Name Type Description <code>response</code> <code>str</code> <p>The response generated by the system.</p> <code>context</code> <code>Optional[str]</code> <p>Additional context for the response, default is an empty string.</p> <code>usage</code> <code>str</code> <p>Usage statistics related to the API call or response.</p> <code>response_json</code> <code>str</code> <p>The JSON representation of the system's response.</p> <code>messages</code> <code>str</code> <p>The messages exchanged during the interaction.</p> <code>type_of_analysis</code> <code>str</code> <p>The type of analysis related to the task.</p> <code>technique</code> <code>Optional[str]</code> <p>The technique used in the analysis, default is an empty string.</p> <code>evaluation</code> <code>Optional[int]</code> <p>An evaluation score for the response, default is 0.</p> <code>observation</code> <code>Optional[str]</code> <p>Observations related to the response, default is an empty string.</p> <code>file_names</code> <code>Optional[str]</code> <p>Names of files related to the response or task, default is an empty string.</p> Source code in <code>model/config_schema.py</code> <pre><code>class SaveRedisPydantic(BaseModel):\n    \"\"\"\n    Represents a data model for saving responses and related information to Redis.\n\n    Attributes:\n        response (str): The response generated by the system.\n        context (Optional[str]): Additional context for the response, default is an empty string.\n        usage (str): Usage statistics related to the API call or response.\n        response_json (str): The JSON representation of the system's response.\n        messages (str): The messages exchanged during the interaction.\n        type_of_analysis (str): The type of analysis related to the task.\n        technique (Optional[str]): The technique used in the analysis, default is an empty string.\n        evaluation (Optional[int]): An evaluation score for the response, default is 0.\n        observation (Optional[str]): Observations related to the response, default is an empty string.\n        file_names (Optional[str]): Names of files related to the response or task, default is an empty string.\n    \"\"\"\n    response: str\n    context: Optional[str] = Field(default=\"\")\n    usage: str\n    response_json: str\n    messages: str\n    type_of_analysis: str\n    technique: Optional[str] = Field(default=\"\")\n    evaluation: Optional[int] = Field(default=0)\n    observation: Optional[str] = Field(default=\"\")\n    file_names: Optional[str] = Field(default=\"\")\n</code></pre>"},{"location":"model/embedding/","title":"Embedding","text":""},{"location":"model/embedding/#model.embedding.InspectorEmbeddings","title":"<code>InspectorEmbeddings</code>","text":"<p>A class to generate and manage embeddings using Azure OpenAI for textual content.</p> <p>Attributes:</p> Name Type Description <code>client</code> <code>AzureOpenAI</code> <p>The AzureOpenAI client configured for embedding generation.</p> <code>embedding_float</code> <code>list</code> <p>The list of generated embeddings in float format.</p> <code>embedding_bytes</code> <code>list</code> <p>The list of generated embeddings in byte format.</p> <code>dimensions</code> <code>int</code> <p>The dimensionality of the generated embeddings.</p> <code>data_to_vectorstore</code> <code>list</code> <p>A list of dictionaries prepared for storing in a vector database.</p> Source code in <code>model/embedding.py</code> <pre><code>class InspectorEmbeddings():\n    \"\"\"\n    A class to generate and manage embeddings using Azure OpenAI for textual content.\n\n    Attributes:\n        client (AzureOpenAI): The AzureOpenAI client configured for embedding generation.\n        embedding_float (list): The list of generated embeddings in float format.\n        embedding_bytes (list): The list of generated embeddings in byte format.\n        dimensions (int): The dimensionality of the generated embeddings.\n        data_to_vectorstore (list): A list of dictionaries prepared for storing in a vector database.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes the InspectorEmbeddings instance and configures the Azure OpenAI client.\n        \"\"\"\n        self.client = None\n        self.embedding_float = None\n        self.embedding_bytes = None\n        self.dimensions = None\n        self.data_to_vectorstore = []\n\n    def create_embedding(\n            self, \n            content: str,\n            dimensions: int = 3072,\n            file_name: str = \"file_name\",\n            chunk_size: int = 8000,\n            service: str = \"azure\",\n        )-&gt;list:\n        \"\"\"\n        Creates embeddings for the given content using Azure OpenAI.\n\n        Args:\n            content (str): The textual content to generate embeddings for.\n            dimensions (int): The number of dimensions for the embeddings. Defaults to 3072.\n            file_name (str): The name of the file associated with the content. Defaults to \"file_name\".\n            chunk_size (int): The maximum size of text chunks. Defaults to 8000.\n            service (str): Service of the LLM. \"azure\" or \"openai\"\n\n        Returns:\n            list: A list of embeddings in float format.\n        \"\"\"\n        self.text_splitted_list = SplitText(chunk_size).split_text(content)\n\n        # Remove blank items\n        text_list = [item for item in self.text_splitted_list if item]\n\n        # Create embeddings with Azure OpenAI\n        try:\n            if service == \"azure\":\n                self.client = AzureOpenAI(\n                    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n                    api_version = os.getenv(\"OPENAI_API_VERSION\"),\n                    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n                    azure_deployment = os.getenv(\"AZURE_EMBEDDING_DEPLOYMENT\"),\n                    )\n            elif service == \"openai\":\n                self.client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))             \n\n            self.embedding = self.client.embeddings.create(\n                input=text_list,\n                model='text-embedding-3-large',\n                dimensions=dimensions,\n            )\n        except Exception as e:\n            raise RuntimeError(f\"Error to create embeddings: {e}\")\n\n        self.embedding_float = [emb.embedding for emb in self.embedding.data]\n        self.embedding_bytes = [np.array(emb, dtype=np.float32).tobytes() for emb in self.embedding_float]\n        self.dimensions = len(self.embedding.data[0].embedding)\n        self.text_list = text_list\n        self.file_name = file_name\n\n        return self.embedding_float\n\n\n    def prepare_data(self)-&gt;list:\n        \"\"\"\n        Prepares the embedding data for storage in a vector database.\n\n        Returns:\n            list: A list of dictionaries containing file information, section number, text, and embedding.\n        \"\"\"\n        for i, text in enumerate(self.text_list):\n            self.data_to_vectorstore.append(\n                {\n                    \"file_name\": self.file_name,\n                    \"section\": i+1,\n                    \"text\": text,\n                    \"embedding\": self.embedding_bytes[i],\n                } \n            )\n        return self.data_to_vectorstore\n</code></pre>"},{"location":"model/embedding/#model.embedding.InspectorEmbeddings.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the InspectorEmbeddings instance and configures the Azure OpenAI client.</p> Source code in <code>model/embedding.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the InspectorEmbeddings instance and configures the Azure OpenAI client.\n    \"\"\"\n    self.client = None\n    self.embedding_float = None\n    self.embedding_bytes = None\n    self.dimensions = None\n    self.data_to_vectorstore = []\n</code></pre>"},{"location":"model/embedding/#model.embedding.InspectorEmbeddings.create_embedding","title":"<code>create_embedding(content, dimensions=3072, file_name='file_name', chunk_size=8000, service='azure')</code>","text":"<p>Creates embeddings for the given content using Azure OpenAI.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The textual content to generate embeddings for.</p> required <code>dimensions</code> <code>int</code> <p>The number of dimensions for the embeddings. Defaults to 3072.</p> <code>3072</code> <code>file_name</code> <code>str</code> <p>The name of the file associated with the content. Defaults to \"file_name\".</p> <code>'file_name'</code> <code>chunk_size</code> <code>int</code> <p>The maximum size of text chunks. Defaults to 8000.</p> <code>8000</code> <code>service</code> <code>str</code> <p>Service of the LLM. \"azure\" or \"openai\"</p> <code>'azure'</code> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of embeddings in float format.</p> Source code in <code>model/embedding.py</code> <pre><code>def create_embedding(\n        self, \n        content: str,\n        dimensions: int = 3072,\n        file_name: str = \"file_name\",\n        chunk_size: int = 8000,\n        service: str = \"azure\",\n    )-&gt;list:\n    \"\"\"\n    Creates embeddings for the given content using Azure OpenAI.\n\n    Args:\n        content (str): The textual content to generate embeddings for.\n        dimensions (int): The number of dimensions for the embeddings. Defaults to 3072.\n        file_name (str): The name of the file associated with the content. Defaults to \"file_name\".\n        chunk_size (int): The maximum size of text chunks. Defaults to 8000.\n        service (str): Service of the LLM. \"azure\" or \"openai\"\n\n    Returns:\n        list: A list of embeddings in float format.\n    \"\"\"\n    self.text_splitted_list = SplitText(chunk_size).split_text(content)\n\n    # Remove blank items\n    text_list = [item for item in self.text_splitted_list if item]\n\n    # Create embeddings with Azure OpenAI\n    try:\n        if service == \"azure\":\n            self.client = AzureOpenAI(\n                api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n                api_version = os.getenv(\"OPENAI_API_VERSION\"),\n                azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n                azure_deployment = os.getenv(\"AZURE_EMBEDDING_DEPLOYMENT\"),\n                )\n        elif service == \"openai\":\n            self.client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))             \n\n        self.embedding = self.client.embeddings.create(\n            input=text_list,\n            model='text-embedding-3-large',\n            dimensions=dimensions,\n        )\n    except Exception as e:\n        raise RuntimeError(f\"Error to create embeddings: {e}\")\n\n    self.embedding_float = [emb.embedding for emb in self.embedding.data]\n    self.embedding_bytes = [np.array(emb, dtype=np.float32).tobytes() for emb in self.embedding_float]\n    self.dimensions = len(self.embedding.data[0].embedding)\n    self.text_list = text_list\n    self.file_name = file_name\n\n    return self.embedding_float\n</code></pre>"},{"location":"model/embedding/#model.embedding.InspectorEmbeddings.prepare_data","title":"<code>prepare_data()</code>","text":"<p>Prepares the embedding data for storage in a vector database.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of dictionaries containing file information, section number, text, and embedding.</p> Source code in <code>model/embedding.py</code> <pre><code>def prepare_data(self)-&gt;list:\n    \"\"\"\n    Prepares the embedding data for storage in a vector database.\n\n    Returns:\n        list: A list of dictionaries containing file information, section number, text, and embedding.\n    \"\"\"\n    for i, text in enumerate(self.text_list):\n        self.data_to_vectorstore.append(\n            {\n                \"file_name\": self.file_name,\n                \"section\": i+1,\n                \"text\": text,\n                \"embedding\": self.embedding_bytes[i],\n            } \n        )\n    return self.data_to_vectorstore\n</code></pre>"},{"location":"model/split_text/","title":"Split text","text":""},{"location":"model/split_text/#model.split_text.SplitText","title":"<code>SplitText</code>","text":"<p>A utility class for splitting large text into smaller chunks using the RecursiveCharacterTextSplitter from the langchain_text_splitters library.</p> <p>Attributes:</p> Name Type Description <code>chunk_size</code> <code>int</code> <p>The maximum size of each text chunk. Defaults to 8000.</p> Source code in <code>model/split_text.py</code> <pre><code>class SplitText:\n    \"\"\"\n    A utility class for splitting large text into smaller chunks using\n    the RecursiveCharacterTextSplitter from the langchain_text_splitters library.\n\n    Attributes:\n        chunk_size (int): The maximum size of each text chunk. Defaults to 8000.\n    \"\"\"\n\n    def __init__(self, chunk_size: int = 8000) -&gt; None:\n        \"\"\"\n        Initializes the SplitText instance with a specified chunk size.\n\n        Args:\n            chunk_size (int): The maximum size of each text chunk. Defaults to 8000.\n        \"\"\"\n\n        self.chunk_size = chunk_size\n\n    def split_text(self, content: str) -&gt; List[str]:\n        \"\"\"\n        Splits the given text into smaller chunks using RecursiveCharacterTextSplitter.\n\n        Args:\n            content (str): The text content to split into chunks.\n\n        Returns:\n            List[str]: A list of text chunks.\n        \"\"\"\n\n        if not isinstance(content, str):\n            raise ValueError(\"The 'content' parameter must be a string.\")\n\n        splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n            chunk_size=self.chunk_size, chunk_overlap=0\n        )\n        return splitter.split_text(content)\n</code></pre>"},{"location":"model/split_text/#model.split_text.SplitText.__init__","title":"<code>__init__(chunk_size=8000)</code>","text":"<p>Initializes the SplitText instance with a specified chunk size.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_size</code> <code>int</code> <p>The maximum size of each text chunk. Defaults to 8000.</p> <code>8000</code> Source code in <code>model/split_text.py</code> <pre><code>def __init__(self, chunk_size: int = 8000) -&gt; None:\n    \"\"\"\n    Initializes the SplitText instance with a specified chunk size.\n\n    Args:\n        chunk_size (int): The maximum size of each text chunk. Defaults to 8000.\n    \"\"\"\n\n    self.chunk_size = chunk_size\n</code></pre>"},{"location":"model/split_text/#model.split_text.SplitText.split_text","title":"<code>split_text(content)</code>","text":"<p>Splits the given text into smaller chunks using RecursiveCharacterTextSplitter.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The text content to split into chunks.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of text chunks.</p> Source code in <code>model/split_text.py</code> <pre><code>def split_text(self, content: str) -&gt; List[str]:\n    \"\"\"\n    Splits the given text into smaller chunks using RecursiveCharacterTextSplitter.\n\n    Args:\n        content (str): The text content to split into chunks.\n\n    Returns:\n        List[str]: A list of text chunks.\n    \"\"\"\n\n    if not isinstance(content, str):\n        raise ValueError(\"The 'content' parameter must be a string.\")\n\n    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n        chunk_size=self.chunk_size, chunk_overlap=0\n    )\n    return splitter.split_text(content)\n</code></pre>"},{"location":"model/tika/","title":"Tika","text":""},{"location":"model/tika/#model.tika.TikaParser","title":"<code>TikaParser</code>","text":"<p>A class for parsing content from files and file bytes using Apache Tika.</p> <p>Attributes:</p> Name Type Description <code>tika_server</code> <code>str</code> <p>The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.</p> Source code in <code>model/tika.py</code> <pre><code>class TikaParser:\n    \"\"\"\n    A class for parsing content from files and file bytes using Apache Tika.\n\n    Attributes:\n        tika_server (str): The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.\n    \"\"\"\n\n    def __init__(self, tika_server: str = 'http://localhost:8002/') -&gt; None:\n        \"\"\"\n        Initializes the TikaParser instance with a Tika server endpoint and starts the Tika Java Virtual Machine.\n\n        Args:\n            tika_server (str): The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.\n        \"\"\"\n        self.tika_server = tika_server\n        tika.initVM()\n\n    def tika_parser_from_bytes(self, file_binary: bytes) -&gt; str:\n        \"\"\"\n        Parses the content of a file provided as bytes using the Tika server.\n\n        Args:\n            file_binary (bytes): The binary content of the file to parse.\n\n        Returns:\n            str: The parsed content of the file.\n        \"\"\"\n        parsed = parser.from_buffer(string=file_binary, serverEndpoint=self.tika_server)\n        self.content = parsed[\"content\"]\n        return self.content\n\n    def tika_parser_from_file_path(self, file_path: str) -&gt; str:\n        \"\"\"\n        Parses the content of a file provided via file path using the Tika server.\n\n        Args:\n            file_path (str): The path to the file to parse.\n\n        Returns:\n            str: The parsed content of the file.\n        \"\"\"\n        parsed = parser.from_file(filename=file_path, serverEndpoint=self.tika_server)\n        self.content = parsed[\"content\"]\n        return self.content\n\n    def hash_file_bytes(self, file_bytes: bytes) -&gt; str:\n        \"\"\"\n        Generates a SHA-256 hash for the given file bytes.\n\n        Args:\n            file_bytes (bytes): The binary content of the file to hash.\n\n        Returns:\n            str: The SHA-256 hash of the file content.\n        \"\"\"\n        sha256_hash = hashlib.sha256()\n        sha256_hash.update(file_bytes)\n        return sha256_hash.hexdigest()\n</code></pre>"},{"location":"model/tika/#model.tika.TikaParser.__init__","title":"<code>__init__(tika_server='http://localhost:8002/')</code>","text":"<p>Initializes the TikaParser instance with a Tika server endpoint and starts the Tika Java Virtual Machine.</p> <p>Parameters:</p> Name Type Description Default <code>tika_server</code> <code>str</code> <p>The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.</p> <code>'http://localhost:8002/'</code> Source code in <code>model/tika.py</code> <pre><code>def __init__(self, tika_server: str = 'http://localhost:8002/') -&gt; None:\n    \"\"\"\n    Initializes the TikaParser instance with a Tika server endpoint and starts the Tika Java Virtual Machine.\n\n    Args:\n        tika_server (str): The endpoint for the Tika server. Defaults to 'http://localhost:8002/'.\n    \"\"\"\n    self.tika_server = tika_server\n    tika.initVM()\n</code></pre>"},{"location":"model/tika/#model.tika.TikaParser.hash_file_bytes","title":"<code>hash_file_bytes(file_bytes)</code>","text":"<p>Generates a SHA-256 hash for the given file bytes.</p> <p>Parameters:</p> Name Type Description Default <code>file_bytes</code> <code>bytes</code> <p>The binary content of the file to hash.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The SHA-256 hash of the file content.</p> Source code in <code>model/tika.py</code> <pre><code>def hash_file_bytes(self, file_bytes: bytes) -&gt; str:\n    \"\"\"\n    Generates a SHA-256 hash for the given file bytes.\n\n    Args:\n        file_bytes (bytes): The binary content of the file to hash.\n\n    Returns:\n        str: The SHA-256 hash of the file content.\n    \"\"\"\n    sha256_hash = hashlib.sha256()\n    sha256_hash.update(file_bytes)\n    return sha256_hash.hexdigest()\n</code></pre>"},{"location":"model/tika/#model.tika.TikaParser.tika_parser_from_bytes","title":"<code>tika_parser_from_bytes(file_binary)</code>","text":"<p>Parses the content of a file provided as bytes using the Tika server.</p> <p>Parameters:</p> Name Type Description Default <code>file_binary</code> <code>bytes</code> <p>The binary content of the file to parse.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The parsed content of the file.</p> Source code in <code>model/tika.py</code> <pre><code>def tika_parser_from_bytes(self, file_binary: bytes) -&gt; str:\n    \"\"\"\n    Parses the content of a file provided as bytes using the Tika server.\n\n    Args:\n        file_binary (bytes): The binary content of the file to parse.\n\n    Returns:\n        str: The parsed content of the file.\n    \"\"\"\n    parsed = parser.from_buffer(string=file_binary, serverEndpoint=self.tika_server)\n    self.content = parsed[\"content\"]\n    return self.content\n</code></pre>"},{"location":"model/tika/#model.tika.TikaParser.tika_parser_from_file_path","title":"<code>tika_parser_from_file_path(file_path)</code>","text":"<p>Parses the content of a file provided via file path using the Tika server.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the file to parse.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The parsed content of the file.</p> Source code in <code>model/tika.py</code> <pre><code>def tika_parser_from_file_path(self, file_path: str) -&gt; str:\n    \"\"\"\n    Parses the content of a file provided via file path using the Tika server.\n\n    Args:\n        file_path (str): The path to the file to parse.\n\n    Returns:\n        str: The parsed content of the file.\n    \"\"\"\n    parsed = parser.from_file(filename=file_path, serverEndpoint=self.tika_server)\n    self.content = parsed[\"content\"]\n    return self.content\n</code></pre>"},{"location":"model/vector_redis/","title":"Vector redis","text":""},{"location":"model/vector_redis/#model.vector_redis.RedisVectorStore","title":"<code>RedisVectorStore</code>","text":"<p>A class for managing a vector store in Redis, including loading data and creating schemas for embeddings.</p> <p>Attributes:</p> Name Type Description <code>redis_url</code> <code>str</code> <p>The URL for connecting to the Redis instance.</p> <code>index</code> <code>SearchIndex</code> <p>The Redis search index instance.</p> <code>keys</code> <code>list</code> <p>The keys loaded into the Redis vector store.</p> <code>info</code> <code>dict</code> <p>Information about the current Redis search index.</p> Source code in <code>model/vector_redis.py</code> <pre><code>class RedisVectorStore():\n    \"\"\"\n    A class for managing a vector store in Redis, including loading data and creating schemas for embeddings.\n\n    Attributes:\n        redis_url (str): The URL for connecting to the Redis instance.\n        index (SearchIndex): The Redis search index instance.\n        keys (list): The keys loaded into the Redis vector store.\n        info (dict): Information about the current Redis search index.\n    \"\"\"\n\n    def __init__(self, redis_url) -&gt; None:\n        \"\"\"\n        Initializes the RedisVectorStore instance with a Redis URL.\n\n        Args:\n            redis_url (str): The Redis connection URL.\n        \"\"\"\n\n        self.redis_url = redis_url\n        self.index = None\n        self.keys = None\n        self.info = None\n\n    def load_data(self, emb_obj: InspectorEmbeddings, config: AppConfig) -&gt; list:\n        \"\"\"\n        Loads data from an embedding object into the Redis vector store.\n\n        Args:\n            emb_obj (InspectorEmbeddings): The embeddings object containing vector data and dimensions.\n            config (AppConfig): The application configuration object.\n\n        Returns:\n            list: A list of keys corresponding to the loaded data in the Redis store.\n        \"\"\"\n\n        if emb_obj != None:\n            data_to_vectorstore = emb_obj.data_to_vectorstore\n            dimensions = emb_obj.dimensions\n            self.create_schema(config, dimensions)\n            self.keys = self.index.load(data_to_vectorstore)\n            return self.keys\n\n    def create_schema(self, config: AppConfig, dimensions: int = 3072, overwrite: bool = True) -&gt; SearchIndex:\n        \"\"\"\n        Creates a schema in Redis for storing document embeddings.\n\n        Args:\n            config (AppConfig): The application configuration object.\n            dimensions (int): The number of dimensions for the vector embeddings. Defaults to 3072.\n            overwrite (bool): Whether to overwrite an existing schema. Defaults to True.\n\n        Returns:\n            SearchIndex: The Redis search index instance.\n\n        \"\"\"\n\n        schema = {\n            \"index\": {\n                \"name\": f\"document-index:{config.user}:{config.task_id}\",\n                \"prefix\": f\"doc:{config.user}:{config.task_id}\",\n                \"storage_type\": \"hash\", \n            },\n            \"fields\": [\n                {\n                    \"name\": \"file_name\",\n                    \"type\": \"tag\"\n                },\n                {\n                    \"name\": \"section\",\n                    \"type\": \"tag\"\n                },\n                {\n                    \"name\": \"text\", \n                    \"type\": \"text\"\n                },\n                {\n                    \"name\": \"embedding\",\n                    \"type\": \"vector\",\n                    \"attrs\": {\n                        \"dims\": dimensions,\n                        \"distance_metric\": \"cosine\",\n                        \"algorithm\": \"flat\",\n                        \"datatype\": \"float32\",\n                    }\n                },\n            ],\n        }\n        self.index = SearchIndex.from_dict(schema)\n        self.index.connect(self.redis_url)\n        self.index.create(overwrite=overwrite)\n        self.info = self.index.info()\n        return self.index\n</code></pre>"},{"location":"model/vector_redis/#model.vector_redis.RedisVectorStore.__init__","title":"<code>__init__(redis_url)</code>","text":"<p>Initializes the RedisVectorStore instance with a Redis URL.</p> <p>Parameters:</p> Name Type Description Default <code>redis_url</code> <code>str</code> <p>The Redis connection URL.</p> required Source code in <code>model/vector_redis.py</code> <pre><code>def __init__(self, redis_url) -&gt; None:\n    \"\"\"\n    Initializes the RedisVectorStore instance with a Redis URL.\n\n    Args:\n        redis_url (str): The Redis connection URL.\n    \"\"\"\n\n    self.redis_url = redis_url\n    self.index = None\n    self.keys = None\n    self.info = None\n</code></pre>"},{"location":"model/vector_redis/#model.vector_redis.RedisVectorStore.create_schema","title":"<code>create_schema(config, dimensions=3072, overwrite=True)</code>","text":"<p>Creates a schema in Redis for storing document embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AppConfig</code> <p>The application configuration object.</p> required <code>dimensions</code> <code>int</code> <p>The number of dimensions for the vector embeddings. Defaults to 3072.</p> <code>3072</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite an existing schema. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>SearchIndex</code> <code>SearchIndex</code> <p>The Redis search index instance.</p> Source code in <code>model/vector_redis.py</code> <pre><code>def create_schema(self, config: AppConfig, dimensions: int = 3072, overwrite: bool = True) -&gt; SearchIndex:\n    \"\"\"\n    Creates a schema in Redis for storing document embeddings.\n\n    Args:\n        config (AppConfig): The application configuration object.\n        dimensions (int): The number of dimensions for the vector embeddings. Defaults to 3072.\n        overwrite (bool): Whether to overwrite an existing schema. Defaults to True.\n\n    Returns:\n        SearchIndex: The Redis search index instance.\n\n    \"\"\"\n\n    schema = {\n        \"index\": {\n            \"name\": f\"document-index:{config.user}:{config.task_id}\",\n            \"prefix\": f\"doc:{config.user}:{config.task_id}\",\n            \"storage_type\": \"hash\", \n        },\n        \"fields\": [\n            {\n                \"name\": \"file_name\",\n                \"type\": \"tag\"\n            },\n            {\n                \"name\": \"section\",\n                \"type\": \"tag\"\n            },\n            {\n                \"name\": \"text\", \n                \"type\": \"text\"\n            },\n            {\n                \"name\": \"embedding\",\n                \"type\": \"vector\",\n                \"attrs\": {\n                    \"dims\": dimensions,\n                    \"distance_metric\": \"cosine\",\n                    \"algorithm\": \"flat\",\n                    \"datatype\": \"float32\",\n                }\n            },\n        ],\n    }\n    self.index = SearchIndex.from_dict(schema)\n    self.index.connect(self.redis_url)\n    self.index.create(overwrite=overwrite)\n    self.info = self.index.info()\n    return self.index\n</code></pre>"},{"location":"model/vector_redis/#model.vector_redis.RedisVectorStore.load_data","title":"<code>load_data(emb_obj, config)</code>","text":"<p>Loads data from an embedding object into the Redis vector store.</p> <p>Parameters:</p> Name Type Description Default <code>emb_obj</code> <code>InspectorEmbeddings</code> <p>The embeddings object containing vector data and dimensions.</p> required <code>config</code> <code>AppConfig</code> <p>The application configuration object.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of keys corresponding to the loaded data in the Redis store.</p> Source code in <code>model/vector_redis.py</code> <pre><code>def load_data(self, emb_obj: InspectorEmbeddings, config: AppConfig) -&gt; list:\n    \"\"\"\n    Loads data from an embedding object into the Redis vector store.\n\n    Args:\n        emb_obj (InspectorEmbeddings): The embeddings object containing vector data and dimensions.\n        config (AppConfig): The application configuration object.\n\n    Returns:\n        list: A list of keys corresponding to the loaded data in the Redis store.\n    \"\"\"\n\n    if emb_obj != None:\n        data_to_vectorstore = emb_obj.data_to_vectorstore\n        dimensions = emb_obj.dimensions\n        self.create_schema(config, dimensions)\n        self.keys = self.index.load(data_to_vectorstore)\n        return self.keys\n</code></pre>"},{"location":"modules/medical/","title":"Medical","text":""},{"location":"modules/medical/#modules.medical.module_medical","title":"<code>module_medical(config)</code>","text":"<p>Extracts specific medical parameters from a data source using a Redis-based RAG pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AppConfig</code> <p>Configuration object containing user, task, and analysis information.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Redis key associated with the result of the RAG pipeline execution.</p> Source code in <code>modules/medical.py</code> <pre><code>def module_medical(config: AppConfig) -&gt; str:\n    \"\"\"\n    Extracts specific medical parameters from a data source using a Redis-based RAG pipeline.\n\n    Args:\n        config (AppConfig): Configuration object containing user, task, and analysis information.\n\n    Returns:\n        str: The Redis key associated with the result of the RAG pipeline execution.\n    \"\"\"\n\n    query = \"\"\"Extract the par\u00e2meters: Creatinine, Hemoglobin, White Blood Cell Count (WBC),Red Blood Cell Count (RBC)\n\tPlatelet Count, Hematocrit, Glucose, Cholesterol (Total), LDL Cholesterol, HDL Cholesterol, Triglycerides, \n    Urea, Blood Urea Nitrogen (BUN), Liver Function Tests (ALT, AST), Bilirubin (Total and Direct), Albumin, \n    Calcium (Serum), Sodium (Serum), Potassium (Serum), Thyroid Stimulating Hormone (TSH)\"\"\"\n\n    rag_redis_key = ct_rag.base_rag_redis_pipeline_controller(\n        prompt=ct_prompts.PROMPT_MEDICAL,\n        query=query,\n        config=config,\n        redis_client=REDIS_CLIENT,\n        k=6,\n        redis_url=REDIS_URL,\n        chunk_size=4000,\n        service=config.service\n        )\n\n    return rag_redis_key\n</code></pre>"},{"location":"view/api/api/","title":"Api","text":""},{"location":"view/api/api/#view.api.api.rag","title":"<code>rag(background_tasks, config, items)</code>  <code>async</code>","text":"<p>Executes a RAG (Retrieval-Augmented Generation) pipeline task asynchronously.</p> <p>This function triggers a background task to run the RAG pipeline using the provided configuration, query, and prompt details. The results are stored in Redis.</p> <p>Parameters:</p> Name Type Description Default <code>background_tasks</code> <code>BackgroundTasks</code> <p>FastAPI's background task manager to handle the asynchronous execution of the RAG pipeline.</p> required <code>config</code> <code>AppConfig</code> <p>Configuration object containing user, task, and analysis details.</p> required <code>items</code> <code>RagItems</code> <p>Object containing the prompt and query for the RAG pipeline.</p> required <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>A JSON response containing the Redis key associated with the RAG task results,</p> <p>e.g., {\"redis_key_response\": }. Source code in <code>view/api/api.py</code> <pre><code>@api.post(\"/rag\")\nasync def rag(background_tasks: BackgroundTasks, config: AppConfig, items: RagItems):\n   \"\"\"\n    Executes a RAG (Retrieval-Augmented Generation) pipeline task asynchronously.\n\n    This function triggers a background task to run the RAG pipeline using the provided\n    configuration, query, and prompt details. The results are stored in Redis.\n\n    Args:\n        background_tasks (BackgroundTasks): FastAPI's background task manager to handle\n            the asynchronous execution of the RAG pipeline.\n        config (AppConfig): Configuration object containing user, task, and analysis details.\n        items (RagItems): Object containing the prompt and query for the RAG pipeline.\n\n    Returns:\n        JSONResponse: A JSON response containing the Redis key associated with the RAG task results,\n        e.g., {\"redis_key_response\": &lt;redis_key&gt;}.\n    \"\"\"\n   redis_key_response = background_tasks.add_task(ct_rag.base_rag_redis_pipeline_controller,\n        prompt=items.prompt,\n        query=items.query,\n        config=config,\n        redis_client=REDIS_CLIENT,\n        k=6,\n        redis_url=REDIS_URL,\n        chunk_size=8000,\n        )\n   return JSONResponse({\"redis_key_response\": redis_key_response})\n</code></pre>"},{"location":"view/api/api/#view.api.api.read_root","title":"<code>read_root()</code>","text":"<p>Root endpoint for the API.</p> <p>This endpoint serves as a simple health check or welcome message for the API.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing a greeting message, e.g., {\"Hello\": \"World\"}.</p> Source code in <code>view/api/api.py</code> <pre><code>@api.get(\"/\")\ndef read_root():\n    \"\"\"\n    Root endpoint for the API.\n\n    This endpoint serves as a simple health check or welcome message for the API.\n\n    Returns:\n        dict: A dictionary containing a greeting message, e.g., {\"Hello\": \"World\"}.\n    \"\"\"\n    return {\"Hello\": \"World\"}\n</code></pre>"},{"location":"view/api/api/#view.api.api.status_user","title":"<code>status_user(user)</code>  <code>async</code>","text":"<p>Retrieves the status of tasks for a given user.</p> <p>This endpoint fetches the current status of all tasks associated with a specific user.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>The identifier of the user whose task status is being queried.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the status of tasks for the user.</p> Source code in <code>view/api/api.py</code> <pre><code>@api.get(\"/status/{user}\")\nasync def status_user(user: str):\n    \"\"\"\n    Retrieves the status of tasks for a given user.\n\n    This endpoint fetches the current status of all tasks associated with a specific user.\n\n    Args:\n        user (str): The identifier of the user whose task status is being queried.\n\n    Returns:\n        dict: A dictionary containing the status of tasks for the user.\n    \"\"\"\n    status = ct_response.status_by_user(user=user)\n    return status\n</code></pre>"},{"location":"view/api/api/#view.api.api.upload","title":"<code>upload(background_tasks, file=File(...), task_id='1234', type_of_analysis='medical', user='user')</code>  <code>async</code>","text":"<p>Handles file upload and processing via a POST endpoint.</p> <p>This endpoint allows users to upload a file for analysis. The type of analysis can be specified as 'medical', 'document', or 'other'. The uploaded file is processed  asynchronously in the background.</p> <p>Parameters:</p> Name Type Description Default <code>background_tasks</code> <code>BackgroundTasks</code> <p>FastAPI's background task manager to handle post-upload processing.</p> required <code>file</code> <code>UploadFile</code> <p>The file to be uploaded. Must be provided in the request.</p> <code>File(...)</code> <code>task_id</code> <code>str</code> <p>An identifier for the task. Defaults to '1234'.</p> <code>'1234'</code> <code>type_of_analysis</code> <code>str</code> <p>Specifies the type of analysis for the uploaded file. Can be 'medical', 'document', or 'other'. Defaults to 'medical'.</p> <code>'medical'</code> <code>user</code> <code>str</code> <p>The user initiating the upload. Defaults to 'user'.</p> <code>'user'</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the key for the uploaded file, e.g., {\"key_file\": uploaded}.</p> Source code in <code>view/api/api.py</code> <pre><code>@api.post(\"/upload\")\nasync def upload(\n    background_tasks: BackgroundTasks,\n    file: UploadFile = File(...), \n    task_id: str = '1234', \n    type_of_analysis: str = 'medical', \n    user: str = 'user',\n    )-&gt;dict:\n    \"\"\"\n        Handles file upload and processing via a POST endpoint.\n\n        This endpoint allows users to upload a file for analysis. The type of analysis can\n        be specified as 'medical', 'document', or 'other'. The uploaded file is processed \n        asynchronously in the background.\n\n        Args:\n            background_tasks (BackgroundTasks): FastAPI's background task manager to handle\n                post-upload processing.\n            file (UploadFile): The file to be uploaded. Must be provided in the request.\n            task_id (str, optional): An identifier for the task. Defaults to '1234'.\n            type_of_analysis (str, optional): Specifies the type of analysis for the uploaded file.\n                Can be 'medical', 'document', or 'other'. Defaults to 'medical'.\n            user (str, optional): The user initiating the upload. Defaults to 'user'.\n\n        Returns:\n            dict: A dictionary containing the key for the uploaded file, e.g., {\"key_file\": uploaded}.\n    \"\"\"\n\n    file_bytes = await file.read()\n    file_name = file.filename.split(\"/\")[-1]\n\n    config = AppConfig(\n        user=user, \n        task_id=task_id,\n        type_of_analysis=type_of_analysis,\n        )\n\n    uploaded = ct_upload.upload_controller(\n        file_bytes=file_bytes,\n        file_name=file_name,\n        config=config,\n    )\n\n    return {\"key_file\": uploaded}\n</code></pre>"},{"location":"view/api/route_medical/","title":"Route medical","text":""},{"location":"view/api/route_medical/#view.api.route_medical.run","title":"<code>run(config, background_tasks)</code>  <code>async</code>","text":"<p>Initiates a medical analysis task asynchronously.</p> <p>This function queues a medical analysis task using the provided configuration.  The task is executed in the background, and the response includes the task ID.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AppConfig</code> <p>Configuration object containing details such as task ID, user,  and analysis type.</p> required <code>background_tasks</code> <code>BackgroundTasks</code> <p>FastAPI's background task manager to handle asynchronous task execution.</p> required <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>A JSON response containing the task ID, e.g., {\"task_id\": }. <p>Raises:</p> Type Description <code>HTTPException</code> <p>If an error occurs while queuing the task, an HTTP 500 error is returned </p> Source code in <code>view/api/route_medical.py</code> <pre><code>@router_medical.post(\"/medical\")\nasync def run(config: AppConfig, background_tasks: BackgroundTasks):\n    \"\"\"\n    Initiates a medical analysis task asynchronously.\n\n    This function queues a medical analysis task using the provided configuration. \n    The task is executed in the background, and the response includes the task ID.\n\n    Args:\n        config (AppConfig): Configuration object containing details such as task ID, user, \n            and analysis type.\n        background_tasks (BackgroundTasks): FastAPI's background task manager to handle\n            asynchronous task execution.\n\n    Returns:\n        JSONResponse: A JSON response containing the task ID, e.g., {\"task_id\": &lt;task_id&gt;}.\n\n    Raises:\n        HTTPException: If an error occurs while queuing the task, an HTTP 500 error is returned \n        with a relevant message.\n    \"\"\"\n    try:\n        background_tasks.add_task(medical.module_medical, config)\n        logger.info(f\"Task {config.task_id} has been queued successfully.\")\n        return JSONResponse({'task_id': config.task_id})\n    except Exception as e:\n        logger.error(f\"Failed to queue task {config.task_id}: {e}\")\n        raise HTTPException(status_code=500, detail=\"An error occurred while queuing the task.\")\n</code></pre>"},{"location":"view/api/route_response/","title":"Route response","text":""},{"location":"view/api/route_response/#view.api.route_responses.get_context","title":"<code>get_context(rag_redis_key=Path(..., description='Redis Key. e.g.: rag:user:8719:medical'))</code>  <code>async</code>","text":"<p>Fetches the context information associated with a Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>Redis key for the analysis.</p> <code>Path(..., description='Redis Key. e.g.: rag:user:8719:medical')</code> <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>Context details.</p> Source code in <code>view/api/route_responses.py</code> <pre><code>@router_response.get(\"/response/context/{rag_redis_key}\")\nasync def get_context(rag_redis_key: str = Path(..., description=\"Redis Key. e.g.: rag:user:8719:medical\")):\n    \"\"\"\n    Fetches the context information associated with a Redis key.\n\n    Args:\n        rag_redis_key (str): Redis key for the analysis.\n\n    Returns:\n        JSONResponse: Context details.\n    \"\"\"\n    try:\n        context = ct_response.context_controller(rag_redis_key)\n        return JSONResponse(content=context)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n</code></pre>"},{"location":"view/api/route_response/#view.api.route_responses.get_detail","title":"<code>get_detail(rag_redis_key=Path(..., description='Redis Key. e.g.: rag:user:8719:medical'))</code>  <code>async</code>","text":"<p>Fetches the detailed response information associated with a Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>Redis key for the analysis.</p> <code>Path(..., description='Redis Key. e.g.: rag:user:8719:medical')</code> <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>Detailed response information.</p> Source code in <code>view/api/route_responses.py</code> <pre><code>@router_response.get(\"/response/detail/{rag_redis_key}\")\nasync def get_detail(rag_redis_key: str = Path(..., description=\"Redis Key. e.g.: rag:user:8719:medical\")):\n    \"\"\"\n    Fetches the detailed response information associated with a Redis key.\n\n    Args:\n        rag_redis_key (str): Redis key for the analysis.\n\n    Returns:\n        JSONResponse: Detailed response information.\n    \"\"\"\n    try:\n        detail = ct_response.detail_controller(rag_redis_key)\n        return JSONResponse(content=detail)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n</code></pre>"},{"location":"view/api/route_response/#view.api.route_responses.get_evaluation","title":"<code>get_evaluation(rag_redis_key=Path(..., description='Redis Key. e.g.: rag:user:8719:medical'))</code>  <code>async</code>","text":"<p>Fetches the evaluation associated with a Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>Redis key for the analysis.</p> <code>Path(..., description='Redis Key. e.g.: rag:user:8719:medical')</code> <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>Evaluation details.</p> Source code in <code>view/api/route_responses.py</code> <pre><code>@router_response.get(\"/response/evaluation/{rag_redis_key}\")\nasync def get_evaluation(rag_redis_key: str = Path(..., description=\"Redis Key. e.g.: rag:user:8719:medical\")):\n    \"\"\"\n    Fetches the evaluation associated with a Redis key.\n\n    Args:\n        rag_redis_key (str): Redis key for the analysis.\n\n    Returns:\n        JSONResponse: Evaluation details.\n    \"\"\"\n    try:\n        evaluation = ct_response.evaluation_controller(rag_redis_key)\n        return JSONResponse(content=evaluation)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n</code></pre>"},{"location":"view/api/route_response/#view.api.route_responses.get_files","title":"<code>get_files(rag_redis_key=Path(..., description='Redis Key. e.g.: rag:user:8719:medical'))</code>  <code>async</code>","text":"<p>Fetches the file names associated with a Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>Redis key for the analysis.</p> <code>Path(..., description='Redis Key. e.g.: rag:user:8719:medical')</code> <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>File names.</p> Source code in <code>view/api/route_responses.py</code> <pre><code>@router_response.get(\"/response/files/{rag_redis_key}\")\nasync def get_files(rag_redis_key: str = Path(..., description=\"Redis Key. e.g.: rag:user:8719:medical\")):\n    \"\"\"\n    Fetches the file names associated with a Redis key.\n\n    Args:\n        rag_redis_key (str): Redis key for the analysis.\n\n    Returns:\n        JSONResponse: File names.\n    \"\"\"\n    try:\n        files = ct_response.file_names_controller(rag_redis_key)\n        return JSONResponse(content=files)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n</code></pre>"},{"location":"view/api/route_response/#view.api.route_responses.get_messages","title":"<code>get_messages(rag_redis_key=Path(..., description='Redis Key. e.g.: rag:user:8719:medical'))</code>  <code>async</code>","text":"<p>Fetches the messages associated with a Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>Redis key for the analysis.</p> <code>Path(..., description='Redis Key. e.g.: rag:user:8719:medical')</code> <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>Message details.</p> Source code in <code>view/api/route_responses.py</code> <pre><code>@router_response.get(\"/response/messages/{rag_redis_key}\")\nasync def get_messages(rag_redis_key: str = Path(..., description=\"Redis Key. e.g.: rag:user:8719:medical\")):\n    \"\"\"\n    Fetches the messages associated with a Redis key.\n\n    Args:\n        rag_redis_key (str): Redis key for the analysis.\n\n    Returns:\n        JSONResponse: Message details.\n    \"\"\"\n    try:\n        messages = ct_response.message_controller(rag_redis_key)\n        return JSONResponse(content=messages)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n</code></pre>"},{"location":"view/api/route_response/#view.api.route_responses.get_response","title":"<code>get_response(rag_redis_key=Path(..., description='Redis Key. e.g.: rag:user:8719:medical'))</code>  <code>async</code>","text":"<p>Fetches the response associated with a Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>Redis key for the analysis.</p> <code>Path(..., description='Redis Key. e.g.: rag:user:8719:medical')</code> <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>The analysis response content.</p> Source code in <code>view/api/route_responses.py</code> <pre><code>@router_response.get(\"/response/{rag_redis_key}\")\nasync def get_response(rag_redis_key: str = Path(..., description=\"Redis Key. e.g.: rag:user:8719:medical\")):\n    \"\"\"\n    Fetches the response associated with a Redis key.\n\n    Args:\n        rag_redis_key (str): Redis key for the analysis.\n\n    Returns:\n        JSONResponse: The analysis response content.\n    \"\"\"\n    try:\n        response = ct_response.response_controller(rag_redis_key)\n        if not response:\n            raise HTTPException(status_code=404, detail=\"Response not found\")\n        return JSONResponse(content=response)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n</code></pre>"},{"location":"view/api/route_response/#view.api.route_responses.get_responses_by_user","title":"<code>get_responses_by_user(user=Path(..., description='User e.g.: user'))</code>  <code>async</code>","text":"<p>Fetches all responses associated with a user.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>User identifier.</p> <code>Path(..., description='User e.g.: user')</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary of responses for the user.</p> Source code in <code>view/api/route_responses.py</code> <pre><code>@router_response.get(\"/response/per-user/{user}\")\nasync def get_responses_by_user(user: str = Path(..., description=\"User e.g.: user\")):\n    \"\"\"\n    Fetches all responses associated with a user.\n\n    Args:\n        user (str): User identifier.\n\n    Returns:\n        dict: A dictionary of responses for the user.\n    \"\"\"\n    try:\n        response = ct_response.responses_by_user(user=user)\n        return response\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n</code></pre>"},{"location":"view/api/route_response/#view.api.route_responses.get_usage","title":"<code>get_usage(rag_redis_key=Path(..., description='Redis Key. e.g.: rag:user:8719:medical'))</code>  <code>async</code>","text":"<p>Fetches the token usage associated with a Redis key.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>Redis key for the analysis.</p> <code>Path(..., description='Redis Key. e.g.: rag:user:8719:medical')</code> <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>Token usage details.</p> Source code in <code>view/api/route_responses.py</code> <pre><code>@router_response.get(\"/response/use/{rag_redis_key}\")\nasync def get_usage(rag_redis_key: str = Path(..., description=\"Redis Key. e.g.: rag:user:8719:medical\")):\n    \"\"\"\n    Fetches the token usage associated with a Redis key.\n\n    Args:\n        rag_redis_key (str): Redis key for the analysis.\n\n    Returns:\n        JSONResponse: Token usage details.\n    \"\"\"\n    try:\n        usage = ct_response.usage_controller(rag_redis_key)\n        return JSONResponse(content=usage)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n</code></pre>"},{"location":"view/api/route_response/#view.api.route_responses.post_evaluation","title":"<code>post_evaluation(rag_redis_key, evaluation_items)</code>  <code>async</code>","text":"<p>Submits an evaluation for a response.</p> <p>Parameters:</p> Name Type Description Default <code>rag_redis_key</code> <code>str</code> <p>Redis key for the analysis.</p> required <code>evaluation_items</code> <code>Evaluation</code> <p>Evaluation data.</p> required <p>Returns:</p> Name Type Description <code>JSONResponse</code> <p>The evaluation result.</p> Source code in <code>view/api/route_responses.py</code> <pre><code>@router_response.post(\"/response/evaluation/{rag_redis_key}\")\nasync def post_evaluation(rag_redis_key: str, evaluation_items: Evaluation):\n    \"\"\"\n    Submits an evaluation for a response.\n\n    Args:\n        rag_redis_key (str): Redis key for the analysis.\n        evaluation_items (Evaluation): Evaluation data.\n\n    Returns:\n        JSONResponse: The evaluation result.\n    \"\"\"\n    try:\n        evaluation = ct_response.evaluation_response(rag_redis_key, evaluation_items)\n        return JSONResponse(content=evaluation)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"An error occurred: {e}\")\n</code></pre>"},{"location":"view/streamlit_app/app/","title":"App","text":""},{"location":"view/streamlit_app/app/#view.streamlit_app.app.load_version","title":"<code>load_version()</code>","text":"<p>Load the application version from a file.</p> Source code in <code>view/streamlit_app/app.py</code> <pre><code>def load_version():\n    \"\"\"Load the application version from a file.\"\"\"\n    version_file_path = 'view/streamlit_app/version.txt'\n    if os.path.exists(version_file_path):\n        with open(version_file_path, \"r\") as f:\n            return f.read().strip()\n    else:\n        return \"Version not found\"\n</code></pre>"},{"location":"view/streamlit_app/app/#view.streamlit_app.app.main","title":"<code>main(user='user')</code>","text":"<p>Main application entry point.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>Default user name for the application.</p> <code>'user'</code> Source code in <code>view/streamlit_app/app.py</code> <pre><code>def main(user='user'):\n    \"\"\"\n    Main application entry point.\n\n    Args:\n        user (str): Default user name for the application.\n    \"\"\"\n    with st.sidebar:\n        st.text(f\"Version: {load_version()}\")\n        option = option_menu(\n            menu_title=\"Inspector\",\n            options=[\n                'Home',\n                'Medical Tests',\n                'Status',\n                'Responses',\n            ],\n            # Icons from https://icons.getbootstrap.com/\n            icons=[\n                'house',\n                'eyeglasses',\n                'easel2',\n                'robot',\n            ],\n        )\n        st.text_input(\n            label='Input your user',\n            value=user,\n            max_chars=50,\n            key='user',\n        )\n\n        st.radio(\n            label=\"Choose the service used in your .env file\",\n            options=[\"azure\", \"openai\"],\n            index=1,\n            disabled=True,\n            key=\"service_option\",\n        )\n\n    # Sidebar navigation logic\n    if option == 'Home':\n        page_home.app()\n    elif option == 'Medical Tests':\n        page_medical.app()\n    elif option == 'Status':\n        page_status.app()\n    elif option == 'Responses':\n        page_responses.app()\n</code></pre>"},{"location":"view/streamlit_app/call_endpoints/","title":"Call endpoints","text":""},{"location":"view/streamlit_app/call_endpoints/#view.streamlit_app.call_endpoints.call_endpoint","title":"<code>call_endpoint(api_route, parameters)</code>","text":"<p>Makes a POST request to a specified API endpoint.</p> <p>This function sends a POST request to the given RAG endpoint with the provided parameters and returns the JSON response.</p> <p>Parameters:</p> Name Type Description Default <code>api_route</code> <code>str</code> <p>The API route to which the POST request is sent.</p> required <code>parameters</code> <code>dict</code> <p>The parameters to be included in the POST request body.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The JSON response from the API.</p> <p>Raises:</p> Type Description <code>RequestException</code> <p>If an error occurs during the HTTP request,</p> Source code in <code>view/streamlit_app/call_endpoints.py</code> <pre><code>def call_endpoint(api_route: str, parameters: dict) -&gt; dict:\n    \"\"\"\n    Makes a POST request to a specified API endpoint.\n\n    This function sends a POST request to the given RAG endpoint with the provided parameters\n    and returns the JSON response.\n\n    Args:\n        api_route (str): The API route to which the POST request is sent.\n        parameters (dict): The parameters to be included in the POST request body.\n\n    Returns:\n        dict: The JSON response from the API.\n\n    Raises:\n        requests.exceptions.RequestException: If an error occurs during the HTTP request,\n        the exception is logged and re-raised.\n    \"\"\"\n    url = f'http://{API_HOST}:{API_PORT}{api_route}'\n    logger.info(f'Sending POST request to {url}')\n    try:\n        response = requests.post(url, json=parameters)\n        response.raise_for_status()\n        response_json = response.json()\n        logger.debug(f'Received response: {response_json}')\n        return response_json\n    except requests.exceptions.RequestException as e:\n        logger.error(f'Request error to {url}: {e}')\n        raise\n</code></pre>"},{"location":"view/streamlit_app/call_endpoints/#view.streamlit_app.call_endpoints.upload_endpoint","title":"<code>upload_endpoint(headers, files, params)</code>","text":"<p>Makes a POST request to upload PDF files to a specified API endpoint.</p> <p>This function sends a file upload request to the <code>/upload</code> endpoint with the provided headers, files, and parameters. It returns the JSON response from the API.</p> <p>Parameters:</p> Name Type Description Default <code>headers</code> <code>dict</code> <p>Headers to include in the POST request, such as authentication tokens.</p> required <code>files</code> <code>dict</code> <p>Files to upload, with keys representing the field names and values as file objects.</p> required <code>params</code> <code>dict</code> <p>Additional parameters to include in the request query string.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The JSON response from the API.</p> <p>Raises:</p> Type Description <code>RequestException</code> <p>If an error occurs during the HTTP request,</p> Source code in <code>view/streamlit_app/call_endpoints.py</code> <pre><code>def upload_endpoint(headers: dict, files: dict, params: dict) -&gt; dict:\n    \"\"\"\n    Makes a POST request to upload PDF files to a specified API endpoint.\n\n    This function sends a file upload request to the `/upload` endpoint with the provided headers,\n    files, and parameters. It returns the JSON response from the API.\n\n    Args:\n        headers (dict): Headers to include in the POST request, such as authentication tokens.\n        files (dict): Files to upload, with keys representing the field names and values as file objects.\n        params (dict): Additional parameters to include in the request query string.\n\n    Returns:\n        dict: The JSON response from the API.\n\n    Raises:\n        requests.exceptions.RequestException: If an error occurs during the HTTP request,\n        the exception is logged and re-raised.\n    \"\"\"\n    url = f'http://{API_HOST}:{API_PORT}/upload'\n    logger.info(f'Sending POST request to {url}')\n    try:\n        response = requests.post(url, headers=headers, files=files, params=params)\n        response.raise_for_status()\n        response_json = response.json()\n        logger.debug(f'Received response: {response_json}')\n        return response_json\n    except requests.exceptions.RequestException as e:\n        logger.error(f'Request error to {url}: {e}')\n        raise\n</code></pre>"},{"location":"view/streamlit_app/page_home/","title":"Page home","text":""},{"location":"view/streamlit_app/page_home/#view.streamlit_app.page_home.app","title":"<code>app()</code>","text":"<p>Render the Home page of the Inspector application.</p> <p>This page provides an overview of the application's features and architecture.</p> Source code in <code>view/streamlit_app/page_home.py</code> <pre><code>def app():\n    \"\"\"\n    Render the Home page of the Inspector application.\n\n    This page provides an overview of the application's features and architecture.\n    \"\"\"\n    st.markdown(\"\"\"\n        # Inspector\n\n        **Inspector** is a Proof of Concept (POC) for a Python-based web application designed to analyze documents.\n\n        ### Key Features:\n        - **Insight Extraction**: Leverages large language models (LLMs) for user-driven document analysis.\n        - **Data Privacy**: Securely handles sensitive data by identifying and masking personal information (e.g., names, document numbers) before transmission to external services.\n        - **Backend and Frontend Integration**:\n            - Backend: Powered by **FastAPI**.\n            - Frontend: Built with **Streamlit**.\n        - **Tooling**:\n            - **Redis** as a vector database for efficient data retrieval.\n            - **Apache Tika** for extracting information from diverse document formats.\n        - **Advanced AI Techniques**:\n            - Retrieval-Augmented Generation (**RAG**).\n            - Advanced prompting strategies like Chain-of-Thought and Tree-of-Thought.\n\n        ### How It Works:\n        Inspector combines cutting-edge AI and robust backend systems to deliver secure, insightful document analysis for sensitive domains such as medical records.\n    \"\"\")\n</code></pre>"},{"location":"view/streamlit_app/page_medical/","title":"Page medical","text":""},{"location":"view/streamlit_app/page_medical/#view.streamlit_app.page_medical.app","title":"<code>app()</code>","text":"<p>Medical Examination Analysis Page.</p> <p>This app allows users to upload files and analyze medical examinations  by sending the file to a backend API.</p> Source code in <code>view/streamlit_app/page_medical.py</code> <pre><code>def app():\n    \"\"\"\n    Medical Examination Analysis Page.\n\n    This app allows users to upload files and analyze medical examinations \n    by sending the file to a backend API.\n    \"\"\"\n    st.title(\"Medical Examination Analysis\")\n    st.markdown(\"\"\"\n                Welcome to the Medical Examination Analysis module.\n                Please upload a document for analysis.\n                \"\"\"\n                )\n\n    st.selectbox(\n        label=\"Choose the language for the response\",\n        options = [\n                    \"\ud83c\uddfa\ud83c\uddf8 English\",\n                    \"\ud83c\udde7\ud83c\uddf7 Portuguese\",\n                    \"\ud83c\uddea\ud83c\uddf8 Spanish\",\n                    \"\ud83c\uddeb\ud83c\uddf7 French\",\n                    \"\ud83c\udde9\ud83c\uddea German\",\n                    \"\ud83c\uddee\ud83c\uddf9 Italian\",\n                    \"\ud83c\udde8\ud83c\uddf3 Chinese (Simplified)\",\n                    \"\ud83c\uddef\ud83c\uddf5 Japanese\",\n                    \"\ud83c\uddf7\ud83c\uddfa Russian\",\n                    \"\ud83c\uddf5\ud83c\uddf1 Polish\",\n                    \"\ud83c\uddf0\ud83c\uddf7 Korean\",\n                    \"\ud83c\uddee\ud83c\uddf3 Hindi\",\n                    \"\ud83c\udde6\ud83c\uddea Arabic\",\n                    \"\ud83c\uddf2\ud83c\uddfd Spanish (Mexico)\",\n                    \"\ud83c\uddff\ud83c\udde6 Zulu\",\n                    \"\ud83c\uddf3\ud83c\uddec Yoruba\",\n                    \"\ud83c\uddf9\ud83c\udded Thai\",\n                    \"\ud83c\uddee\ud83c\udde9 Indonesian\",\n                    \"\ud83c\uddf5\ud83c\udded Filipino\",\n                    \"\ud83c\udde8\ud83c\udde6 English (Canada)\",\n                    \"\ud83c\udde6\ud83c\uddfa English (Australia)\"\n                ],\n        index=0,\n        key=\"language_option\"\n    )\n\n    uploaded_file = st.file_uploader(\n        label=\"Upload your document here\",  \n        # type=['pdf', 'docx', 'xlsx', 'csv', 'md', 'txt'], \n        key='uploaded_file', \n        accept_multiple_files=False\n        )\n\n    if uploaded_file:\n        button_run = st.button('Run Analysis')\n        if button_run:\n            type_of_analysis = 'medical'\n            task_id = str(random.randint(0, 9999))  # Generate a random task ID\n\n            if 'user' not in st.session_state:\n                st.session_state['user'] = 'default_user'\n\n            try:\n                response_upload = upload_file(uploaded_file, task_id, type_of_analysis, st.session_state['user'])\n                if response_upload:\n                    parameters = {\n                        \"user\": st.session_state['user'],\n                        \"task_id\": task_id,\n                        \"type_of_analysis\": type_of_analysis,\n                        \"service\": st.session_state[\"service_option\"],\n                        \"language\": st.session_state[\"language_option\"]\n                    }\n                    st.write(\"Parameters sent for analysis:\", parameters)\n\n                    api_route = '/medical'\n                    task_response = call_endpoint(api_route, parameters)\n                    if task_response.get('error'):\n                        st.error(f\"Error: {task_response['error']}\")\n                    else:\n                        st.success(\"Successfully sent for analysis! Check the status and response in the side menu.\")\n                else:\n                    st.error(\"Failed to upload the file. Please try again.\")\n            except Exception as e:\n                st.error(f\"An unexpected error occurred: {e}\")\n</code></pre>"},{"location":"view/streamlit_app/page_responses/","title":"Page responses","text":""},{"location":"view/streamlit_app/page_responses/#view.streamlit_app.page_responses.app","title":"<code>app()</code>","text":"<p>Render the Response page of the AI model.</p> <p>This page displays completed analyses and allows users to review responses,  view related metadata, and submit evaluations.</p> Source code in <code>view/streamlit_app/page_responses.py</code> <pre><code>def app():\n    \"\"\"\n    Render the Response page of the AI model.\n\n    This page displays completed analyses and allows users to review responses, \n    view related metadata, and submit evaluations.\n    \"\"\"\n    st.title(\"AI Model Responses\")\n    st.write(\"\u26a0\ufe0f Only completed analyses are displayed here. Track the status of your analysis in the status menu.\")\n\n    # Fetch status dataframe\n    df = check_status()\n    if not df.empty:\n        df = df[df['Result'] == '\u2705']\n        total_response = df[\"Identifier\"].to_list()\n        total_response = [identifier.replace('status', 'response') for identifier in total_response]\n\n        if total_response:\n            rag_redis_key = st.selectbox(\n                label='Select a key or enter the number to view the response', \n                options=total_response\n            )\n\n            # Display AI responses and metadata\n            st.markdown(\"## Model Response\")\n            response_data = fetch_api_data(f'http://{API_HOST}:{API_PORT}/response/{rag_redis_key}')\n            st.write(response_data)\n\n            st.markdown(\"## Tokens\")\n            tokens_data = fetch_api_data(f'http://{API_HOST}:{API_PORT}/response/use/{rag_redis_key}')\n            st.json(tokens_data, expanded=False)\n\n            st.markdown(\"## Context\")\n            context_data = fetch_api_data(f'http://{API_HOST}:{API_PORT}/response/context/{rag_redis_key}')\n            st.json(context_data, expanded=False)\n\n            st.markdown(\"## Files Used\")\n            files_data = fetch_api_data(f'http://{API_HOST}:{API_PORT}/response/files/{rag_redis_key}')\n            st.json(files_data, expanded=False)\n\n            st.markdown(\"## Detailed Prompt\")\n            prompt_data = fetch_api_data(f'http://{API_HOST}:{API_PORT}/response/messages/{rag_redis_key}')\n            st.json(prompt_data, expanded=False)\n\n            st.markdown(\"## Detailed Response\")\n            details_data = fetch_api_data(f'http://{API_HOST}:{API_PORT}/response/detail/{rag_redis_key}')\n            st.json(details_data, expanded=False)\n\n            st.markdown(\"## Response Evaluation\")\n            evaluation_data = fetch_api_data(f'http://{API_HOST}:{API_PORT}/response/evaluation/{rag_redis_key}')\n            st.json(evaluation_data, expanded=False)\n\n            if evaluation_data.get(\"evaluation\") == 0:\n                evaluation_score = st.slider(\n                    label=\"Evaluate the Model Response:\", \n                    min_value=0, \n                    max_value=5, \n                    step=1, \n                    help=\"0 - Not Evaluated, 1 - Nonsensical, 2 - Very Incomplete, 3 - Incomplete, 4 - Acceptable, 5 - Complete\",\n                    key=\"evaluation_slider\"\n                )\n                observation = st.text_area(\n                    label=\"What would be the expected response? (Required for ratings 1 to 3)\", \n                    key=\"evaluation_observation\",\n                )\n                if st.button(\"Submit Evaluation\"):\n                    if evaluation_score in [1, 2, 3] and not observation.strip():\n                        st.error(\"Observation is required for evaluations rated 1 to 3.\")\n                    else:\n                        url_post = f'http://{API_HOST}:{API_PORT}/response/evaluation/{rag_redis_key}'\n                        params = {\n                            \"evaluation\": int(evaluation_score),\n                            \"observation\": observation\n                        }\n                        try:\n                            evaluation_post = requests.post(url_post, json=params)\n                            evaluation_post.raise_for_status()\n                            st.success(\"Evaluation Submitted Successfully!\")\n                        except requests.RequestException as e:\n                            st.error(f\"Failed to submit evaluation: {e}\")\n        else:\n            st.warning(f\"No keys found for the user: {st.session_state.get('user', 'unknown')}\")\n\n    else:\n        st.info(\"No completed analyses available.\")\n</code></pre>"},{"location":"view/streamlit_app/page_responses/#view.streamlit_app.page_responses.fetch_api_data","title":"<code>fetch_api_data(endpoint)</code>","text":"<p>Fetch data from the API.</p> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>str</code> <p>The API endpoint URL.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>The JSON response from the API or an error message.</p> Source code in <code>view/streamlit_app/page_responses.py</code> <pre><code>def fetch_api_data(endpoint: str):\n    \"\"\"\n    Fetch data from the API.\n\n    Args:\n        endpoint (str): The API endpoint URL.\n\n    Returns:\n        dict: The JSON response from the API or an error message.\n    \"\"\"\n    try:\n        response = requests.get(endpoint)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        st.error(f\"Failed to fetch data from {endpoint}: {e}\")\n        return {}\n</code></pre>"},{"location":"view/streamlit_app/page_status/","title":"Page status","text":""},{"location":"view/streamlit_app/page_status/#view.streamlit_app.page_status.app","title":"<code>app()</code>","text":"<p>Render the Status page for analysis.</p> Source code in <code>view/streamlit_app/page_status.py</code> <pre><code>def app():\n    \"\"\"Render the Status page for analysis.\"\"\"\n    st.title('Analysis Status')\n    st.write(\"\"\"\n             Displays the processing status of the last five analyses.\n             Check \"Show all\" to display all tasks or click \"Refresh\" to update the status.\n             \"\"\")\n    df = check_status()\n    if not df.empty:\n        st.button(label=\"Refresh\", key=\"button_refresh\")\n        st.checkbox(\"Show all\", key=\"check_all\")\n\n        if st.session_state[\"button_refresh\"]:   \n            if st.session_state[\"check_all\"]:\n                st.dataframe(data=df, hide_index=True)\n            else:\n                st.dataframe(data=df.head(5), hide_index=True)\n    else:\n        st.warning(f\"No tasks found for the user: {st.session_state[\"user\"]}\")\n</code></pre>"},{"location":"view/streamlit_app/page_status/#view.streamlit_app.page_status.check_status","title":"<code>check_status()</code>","text":"<p>Fetch the status of analyses for the current user.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: A DataFrame containing analysis IDs, statuses, timestamps, and results.</p> Source code in <code>view/streamlit_app/page_status.py</code> <pre><code>def check_status():\n    \"\"\"\n    Fetch the status of analyses for the current user.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing analysis IDs, statuses, timestamps, and results.\n    \"\"\"\n    user = st.session_state.get('user', 'default_user')\n    url = f'http://{API_HOST}:{API_PORT}/status/{user}'\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Raise HTTP errors if they occur\n        total_response = response.json()\n\n        if total_response:\n            df = pd.DataFrame(list(total_response.items()), columns=[\"Identifier\", \"Status\"])\n            df[\"Timestamp\"] = pd.to_datetime(df[\"Status\"].str.extract(r'at (.*)')[0], errors='coerce')\n            df[\"Result\"] = df[\"Status\"].apply(\n                lambda x: \"\u2705\" if \"Concluded\" in x else (\"\u274c\" if \"Error\" in x else \"\u23f3\")\n            )\n            df = df.sort_values(by=\"Timestamp\", ascending=False)\n            return df\n        else:\n            return pd.DataFrame()  # Return empty DataFrame if no data is found\n    except requests.RequestException as e:\n        st.error(f\"Failed to fetch status data: {e}\")\n        return pd.DataFrame()  # Return empty DataFrame in case of an error\n</code></pre>"},{"location":"view/streamlit_app/upload/","title":"Upload","text":""},{"location":"view/streamlit_app/upload/#view.streamlit_app.upload.upload_file","title":"<code>upload_file(uploaded_file, id, type_of_analysis, user)</code>","text":"<p>Uploads the file for analysis.</p> <p>Parameters:</p> Name Type Description Default <code>uploaded_file</code> <code>Any</code> <p>The file object to be uploaded.</p> required <code>id</code> <code>str</code> <p>Unique identifier for the task.</p> required <code>type_of_analysis</code> <code>str</code> <p>The type of analysis to be performed.</p> required <code>user</code> <code>str</code> <p>The username or identifier of the user.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict</code> <p>The response from the API after the upload request.</p> Source code in <code>view/streamlit_app/upload.py</code> <pre><code>def upload_file(uploaded_file: Any, id: str, type_of_analysis: str, user: str) -&gt; Dict:\n    \"\"\"\n    Uploads the file for analysis.\n\n    Args:\n        uploaded_file (Any): The file object to be uploaded.\n        id (str): Unique identifier for the task.\n        type_of_analysis (str): The type of analysis to be performed.\n        user (str): The username or identifier of the user.\n\n    Returns:\n        dict: The response from the API after the upload request.\n    \"\"\"\n    headers = {\n        'accept': 'application/json',\n    }\n    files = {\n        'file': (\n            uploaded_file.name,\n            uploaded_file,\n            uploaded_file.type,\n        ),\n    }\n    params = {\n        'task_id': id,\n        'type_of_analysis': type_of_analysis,\n        'user': user\n    }\n\n    try:\n        response_request = upload_endpoint(headers, files, params)\n        return response_request\n    except Exception as e:\n        return {\"error\": f\"File upload failed: {e}\"}\n</code></pre>"}]}